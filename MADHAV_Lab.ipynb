{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: librosa in /opt/anaconda3/lib/python3.12/site-packages (0.10.2.post1)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.12/site-packages (3.8.4)\n",
      "Collecting tensorflow-macos\n",
      "  Using cached tensorflow_macos-2.16.2-cp312-cp312-macosx_12_0_arm64.whl.metadata (3.3 kB)\n",
      "Collecting tensorflow-metal\n",
      "  Using cached tensorflow_metal-1.2.0-cp312-cp312-macosx_12_0_arm64.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /opt/anaconda3/lib/python3.12/site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from librosa) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /opt/anaconda3/lib/python3.12/site-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: joblib>=0.14 in /opt/anaconda3/lib/python3.12/site-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in /opt/anaconda3/lib/python3.12/site-packages (from librosa) (0.59.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /opt/anaconda3/lib/python3.12/site-packages (from librosa) (0.13.1)\n",
      "Requirement already satisfied: pooch>=1.1 in /opt/anaconda3/lib/python3.12/site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /opt/anaconda3/lib/python3.12/site-packages (from librosa) (0.5.0.post1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from librosa) (4.11.0)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in /opt/anaconda3/lib/python3.12/site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from librosa) (1.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (3.0.9)\n",
      "Collecting tensorflow==2.16.2 (from tensorflow-macos)\n",
      "  Using cached tensorflow-2.16.2-cp312-cp312-macosx_12_0_arm64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow==2.16.2->tensorflow-macos) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow==2.16.2->tensorflow-macos) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow==2.16.2->tensorflow-macos) (25.1.24)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow==2.16.2->tensorflow-macos) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow==2.16.2->tensorflow-macos) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow==2.16.2->tensorflow-macos) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow==2.16.2->tensorflow-macos) (18.1.1)\n",
      "Collecting ml-dtypes~=0.3.1 (from tensorflow==2.16.2->tensorflow-macos)\n",
      "  Using cached ml_dtypes-0.3.2-cp312-cp312-macosx_10_9_universal2.whl.metadata (20 kB)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow==2.16.2->tensorflow-macos) (3.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow==2.16.2->tensorflow-macos) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow==2.16.2->tensorflow-macos) (2.32.2)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow==2.16.2->tensorflow-macos) (69.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow==2.16.2->tensorflow-macos) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow==2.16.2->tensorflow-macos) (2.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow==2.16.2->tensorflow-macos) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow==2.16.2->tensorflow-macos) (1.70.0)\n",
      "Collecting tensorboard<2.17,>=2.16 (from tensorflow==2.16.2->tensorflow-macos)\n",
      "  Using cached tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: keras>=3.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow==2.16.2->tensorflow-macos) (3.8.0)\n",
      "Requirement already satisfied: wheel~=0.35 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow-metal) (0.43.0)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /opt/anaconda3/lib/python3.12/site-packages (from numba>=0.51.0->librosa) (0.42.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from pooch>=1.1->librosa) (3.10.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn>=0.20.0->librosa) (2.2.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /opt/anaconda3/lib/python3.12/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Requirement already satisfied: rich in /opt/anaconda3/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow==2.16.2->tensorflow-macos) (13.3.5)\n",
      "Requirement already satisfied: namex in /opt/anaconda3/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow==2.16.2->tensorflow-macos) (0.0.8)\n",
      "Requirement already satisfied: optree in /opt/anaconda3/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow==2.16.2->tensorflow-macos) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.2->tensorflow-macos) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.2->tensorflow-macos) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.2->tensorflow-macos) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.2->tensorflow-macos) (2024.7.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.2->tensorflow-macos) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.2->tensorflow-macos) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.2->tensorflow-macos) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow==2.16.2->tensorflow-macos) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich->keras>=3.0.0->tensorflow==2.16.2->tensorflow-macos) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich->keras>=3.0.0->tensorflow==2.16.2->tensorflow-macos) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.12/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.0.0->tensorflow==2.16.2->tensorflow-macos) (0.1.0)\n",
      "Using cached tensorflow_macos-2.16.2-cp312-cp312-macosx_12_0_arm64.whl (2.1 kB)\n",
      "Using cached tensorflow-2.16.2-cp312-cp312-macosx_12_0_arm64.whl (227.1 MB)\n",
      "Using cached tensorflow_metal-1.2.0-cp312-cp312-macosx_12_0_arm64.whl (1.4 MB)\n",
      "Using cached ml_dtypes-0.3.2-cp312-cp312-macosx_10_9_universal2.whl (393 kB)\n",
      "Using cached tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "Installing collected packages: tensorflow-metal, ml-dtypes, tensorboard, tensorflow, tensorflow-macos\n",
      "  Attempting uninstall: ml-dtypes\n",
      "    Found existing installation: ml-dtypes 0.4.1\n",
      "    Uninstalling ml-dtypes-0.4.1:\n",
      "      Successfully uninstalled ml-dtypes-0.4.1\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.18.0\n",
      "    Uninstalling tensorboard-2.18.0:\n",
      "      Successfully uninstalled tensorboard-2.18.0\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.18.0\n",
      "    Uninstalling tensorflow-2.18.0:\n",
      "      Successfully uninstalled tensorflow-2.18.0\n",
      "Successfully installed ml-dtypes-0.3.2 tensorboard-2.16.2 tensorflow-2.16.2 tensorflow-macos-2.16.2 tensorflow-metal-1.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install librosa numpy pandas matplotlib tensorflow-macos tensorflow-metal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, BatchNormalization, ReLU, Dropout, Dense, Lambda\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Define paths\n",
    "dataset_path = \"/Users/aaryan/Downloads/6967442\"  \n",
    "train_metadata_path = os.path.join(dataset_path, \"metadata of train set .csv\")\n",
    "test_metadata_path = os.path.join(dataset_path, \"metadata of test set.csv\")\n",
    "train_folder = os.path.join(dataset_path, \"train\")\n",
    "test_folder = os.path.join(dataset_path, \"test\")\n",
    "\n",
    "# Load metadata\n",
    "train_metadata = pd.read_csv(train_metadata_path)\n",
    "test_metadata = pd.read_csv(test_metadata_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio parameters\n",
    "SAMPLE_RATE = 8000\n",
    "AUDIO_LENGTH = 4 * SAMPLE_RATE  # 4 seconds * 8000 Hz\n",
    "NUM_CLASSES = train_metadata['Class ID'].nunique()\n",
    "def load_training_audio(filename):\n",
    "    \"\"\"Load and preprocess audio file\"\"\"\n",
    "    filepath = os.path.join(train_folder, filename)\n",
    "    signal, _ = librosa.load(filepath, sr=SAMPLE_RATE)\n",
    "    \n",
    "    # Zero-pad if shorter than required length\n",
    "    if len(signal) < AUDIO_LENGTH:\n",
    "        pad_length = AUDIO_LENGTH - len(signal)\n",
    "        signal = np.pad(signal, (0, pad_length))\n",
    "    else:\n",
    "        signal = signal[:AUDIO_LENGTH]  # Truncate if longer\n",
    "    \n",
    "    return signal.reshape(-1, 1)  # Reshape for Conv1D\n",
    "\n",
    "def load_testing_audio(filename):\n",
    "    \"\"\"Load and preprocess audio file\"\"\"\n",
    "    filepath = os.path.join(test_folder, filename)\n",
    "    signal, _ = librosa.load(filepath, sr=SAMPLE_RATE)\n",
    "    \n",
    "    # Zero-pad if shorter than required length\n",
    "    if len(signal) < AUDIO_LENGTH:\n",
    "        pad_length = AUDIO_LENGTH - len(signal)\n",
    "        signal = np.pad(signal, (0, pad_length))\n",
    "    else:\n",
    "        signal = signal[:AUDIO_LENGTH]  # Truncate if longer\n",
    "    \n",
    "    return signal.reshape(-1, 1)  # Reshape for Conv1D\n",
    "\n",
    "\n",
    "# Prepare dataset\n",
    "def prepare_train_data(metadata):\n",
    "    X, y = [], []\n",
    "    for _, row in metadata.iterrows():\n",
    "        audio = load_training_audio(row['Filename'])\n",
    "        X.append(audio)\n",
    "        y.append(row['Class ID'])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def prepare_test_data(metadata):\n",
    "    X, y = [], []\n",
    "    for _, row in metadata.iterrows():\n",
    "        audio = load_testing_audio(row['Filename'])\n",
    "        X.append(audio)\n",
    "        y.append(row['Class_id'])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X_train, y_train = prepare_train_data(train_metadata)\n",
    "X_test, y_test = prepare_test_data(test_metadata)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS backend for training\n"
     ]
    }
   ],
   "source": [
    "if tf.config.list_physical_devices('GPU'):\n",
    "    tf.config.experimental.set_memory_growth(tf.config.list_physical_devices('GPU')[0], True)\n",
    "    print(\"Using MPS backend for training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.3365 - loss: 1.7306\n",
      "Epoch 1: val_loss improved from inf to 1.92385, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 203ms/step - accuracy: 0.3369 - loss: 1.7298 - val_accuracy: 0.2687 - val_loss: 1.9239\n",
      "Epoch 2/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.4769 - loss: 1.4017\n",
      "Epoch 2: val_loss did not improve from 1.92385\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 184ms/step - accuracy: 0.4770 - loss: 1.4016 - val_accuracy: 0.2719 - val_loss: 2.1204\n",
      "Epoch 3/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.5232 - loss: 1.2826\n",
      "Epoch 3: val_loss improved from 1.92385 to 1.82287, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 184ms/step - accuracy: 0.5231 - loss: 1.2827 - val_accuracy: 0.3076 - val_loss: 1.8229\n",
      "Epoch 4/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.5432 - loss: 1.2098\n",
      "Epoch 4: val_loss improved from 1.82287 to 1.38182, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 184ms/step - accuracy: 0.5432 - loss: 1.2098 - val_accuracy: 0.4714 - val_loss: 1.3818\n",
      "Epoch 5/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.5673 - loss: 1.1490\n",
      "Epoch 5: val_loss improved from 1.38182 to 1.18515, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 184ms/step - accuracy: 0.5673 - loss: 1.1491 - val_accuracy: 0.5564 - val_loss: 1.1852\n",
      "Epoch 6/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.5750 - loss: 1.1411\n",
      "Epoch 6: val_loss improved from 1.18515 to 1.11795, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 184ms/step - accuracy: 0.5751 - loss: 1.1410 - val_accuracy: 0.5787 - val_loss: 1.1179\n",
      "Epoch 7/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.5857 - loss: 1.1198\n",
      "Epoch 7: val_loss improved from 1.11795 to 1.07021, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 184ms/step - accuracy: 0.5858 - loss: 1.1196 - val_accuracy: 0.6002 - val_loss: 1.0702\n",
      "Epoch 8/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.6058 - loss: 1.0484\n",
      "Epoch 8: val_loss improved from 1.07021 to 1.04724, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 182ms/step - accuracy: 0.6058 - loss: 1.0484 - val_accuracy: 0.6129 - val_loss: 1.0472\n",
      "Epoch 9/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.6158 - loss: 1.0293\n",
      "Epoch 9: val_loss improved from 1.04724 to 1.02030, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 183ms/step - accuracy: 0.6158 - loss: 1.0292 - val_accuracy: 0.6200 - val_loss: 1.0203\n",
      "Epoch 10/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.6202 - loss: 1.0083\n",
      "Epoch 10: val_loss improved from 1.02030 to 0.98810, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 186ms/step - accuracy: 0.6202 - loss: 1.0082 - val_accuracy: 0.6542 - val_loss: 0.9881\n",
      "Epoch 11/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.6423 - loss: 0.9875\n",
      "Epoch 11: val_loss improved from 0.98810 to 0.97124, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 185ms/step - accuracy: 0.6423 - loss: 0.9874 - val_accuracy: 0.6606 - val_loss: 0.9712\n",
      "Epoch 12/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.6598 - loss: 0.9263\n",
      "Epoch 12: val_loss improved from 0.97124 to 0.93498, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 183ms/step - accuracy: 0.6597 - loss: 0.9264 - val_accuracy: 0.6741 - val_loss: 0.9350\n",
      "Epoch 13/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.6623 - loss: 0.9236\n",
      "Epoch 13: val_loss improved from 0.93498 to 0.90253, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 184ms/step - accuracy: 0.6623 - loss: 0.9235 - val_accuracy: 0.6987 - val_loss: 0.9025\n",
      "Epoch 14/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.6740 - loss: 0.8851\n",
      "Epoch 14: val_loss improved from 0.90253 to 0.87417, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 185ms/step - accuracy: 0.6740 - loss: 0.8851 - val_accuracy: 0.6916 - val_loss: 0.8742\n",
      "Epoch 15/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.6817 - loss: 0.8645\n",
      "Epoch 15: val_loss did not improve from 0.87417\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 187ms/step - accuracy: 0.6817 - loss: 0.8645 - val_accuracy: 0.6836 - val_loss: 0.8921\n",
      "Epoch 16/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.6900 - loss: 0.8277\n",
      "Epoch 16: val_loss did not improve from 0.87417\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 187ms/step - accuracy: 0.6900 - loss: 0.8278 - val_accuracy: 0.6876 - val_loss: 0.8918\n",
      "Epoch 17/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.6941 - loss: 0.8274\n",
      "Epoch 17: val_loss improved from 0.87417 to 0.84592, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 188ms/step - accuracy: 0.6941 - loss: 0.8273 - val_accuracy: 0.7043 - val_loss: 0.8459\n",
      "Epoch 18/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.6975 - loss: 0.8230\n",
      "Epoch 18: val_loss improved from 0.84592 to 0.83958, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 187ms/step - accuracy: 0.6976 - loss: 0.8229 - val_accuracy: 0.7083 - val_loss: 0.8396\n",
      "Epoch 19/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.7256 - loss: 0.7883\n",
      "Epoch 19: val_loss did not improve from 0.83958\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 186ms/step - accuracy: 0.7256 - loss: 0.7883 - val_accuracy: 0.7003 - val_loss: 0.8634\n",
      "Epoch 20/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.7113 - loss: 0.7789\n",
      "Epoch 20: val_loss improved from 0.83958 to 0.82497, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 185ms/step - accuracy: 0.7113 - loss: 0.7789 - val_accuracy: 0.7114 - val_loss: 0.8250\n",
      "Epoch 21/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.7260 - loss: 0.7631\n",
      "Epoch 21: val_loss did not improve from 0.82497\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 184ms/step - accuracy: 0.7260 - loss: 0.7631 - val_accuracy: 0.7114 - val_loss: 0.8766\n",
      "Epoch 22/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.7292 - loss: 0.7438\n",
      "Epoch 22: val_loss did not improve from 0.82497\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 184ms/step - accuracy: 0.7292 - loss: 0.7438 - val_accuracy: 0.6916 - val_loss: 0.9114\n",
      "Epoch 23/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.7280 - loss: 0.7568\n",
      "Epoch 23: val_loss did not improve from 0.82497\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 185ms/step - accuracy: 0.7280 - loss: 0.7567 - val_accuracy: 0.7186 - val_loss: 0.8362\n",
      "Epoch 24/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.7455 - loss: 0.7174\n",
      "Epoch 24: val_loss improved from 0.82497 to 0.81093, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 184ms/step - accuracy: 0.7454 - loss: 0.7174 - val_accuracy: 0.7242 - val_loss: 0.8109\n",
      "Epoch 25/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.7365 - loss: 0.7143\n",
      "Epoch 25: val_loss did not improve from 0.81093\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 183ms/step - accuracy: 0.7365 - loss: 0.7143 - val_accuracy: 0.7266 - val_loss: 0.8197\n",
      "Epoch 26/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.7436 - loss: 0.7073\n",
      "Epoch 26: val_loss did not improve from 0.81093\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 183ms/step - accuracy: 0.7436 - loss: 0.7073 - val_accuracy: 0.7202 - val_loss: 0.8503\n",
      "Epoch 27/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.7558 - loss: 0.6801\n",
      "Epoch 27: val_loss did not improve from 0.81093\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 186ms/step - accuracy: 0.7557 - loss: 0.6802 - val_accuracy: 0.7258 - val_loss: 0.8327\n",
      "Epoch 28/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.7438 - loss: 0.7226\n",
      "Epoch 28: val_loss improved from 0.81093 to 0.78624, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 189ms/step - accuracy: 0.7438 - loss: 0.7225 - val_accuracy: 0.7329 - val_loss: 0.7862\n",
      "Epoch 29/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.7588 - loss: 0.6861\n",
      "Epoch 29: val_loss did not improve from 0.78624\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 188ms/step - accuracy: 0.7588 - loss: 0.6861 - val_accuracy: 0.7130 - val_loss: 0.8904\n",
      "Epoch 30/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.7593 - loss: 0.6711\n",
      "Epoch 30: val_loss improved from 0.78624 to 0.75984, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 187ms/step - accuracy: 0.7593 - loss: 0.6710 - val_accuracy: 0.7417 - val_loss: 0.7598\n",
      "Epoch 31/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.7724 - loss: 0.6574\n",
      "Epoch 31: val_loss improved from 0.75984 to 0.75306, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 184ms/step - accuracy: 0.7724 - loss: 0.6574 - val_accuracy: 0.7504 - val_loss: 0.7531\n",
      "Epoch 32/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.7821 - loss: 0.6259\n",
      "Epoch 32: val_loss did not improve from 0.75306\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 184ms/step - accuracy: 0.7820 - loss: 0.6261 - val_accuracy: 0.7409 - val_loss: 0.7583\n",
      "Epoch 33/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.7765 - loss: 0.6502\n",
      "Epoch 33: val_loss did not improve from 0.75306\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 184ms/step - accuracy: 0.7764 - loss: 0.6502 - val_accuracy: 0.7250 - val_loss: 0.9152\n",
      "Epoch 34/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.7581 - loss: 0.6609\n",
      "Epoch 34: val_loss did not improve from 0.75306\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 183ms/step - accuracy: 0.7582 - loss: 0.6608 - val_accuracy: 0.7464 - val_loss: 0.7794\n",
      "Epoch 35/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.7888 - loss: 0.6162\n",
      "Epoch 35: val_loss did not improve from 0.75306\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 184ms/step - accuracy: 0.7887 - loss: 0.6163 - val_accuracy: 0.7162 - val_loss: 0.9540\n",
      "Epoch 36/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.7810 - loss: 0.6415\n",
      "Epoch 36: val_loss did not improve from 0.75306\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 183ms/step - accuracy: 0.7810 - loss: 0.6415 - val_accuracy: 0.7369 - val_loss: 0.8675\n",
      "Epoch 37/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.7802 - loss: 0.6223\n",
      "Epoch 37: val_loss did not improve from 0.75306\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 183ms/step - accuracy: 0.7802 - loss: 0.6223 - val_accuracy: 0.7536 - val_loss: 0.7821\n",
      "Epoch 38/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.7768 - loss: 0.6187\n",
      "Epoch 38: val_loss did not improve from 0.75306\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 185ms/step - accuracy: 0.7768 - loss: 0.6187 - val_accuracy: 0.7480 - val_loss: 0.7875\n",
      "Epoch 39/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.7868 - loss: 0.6005\n",
      "Epoch 39: val_loss did not improve from 0.75306\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 184ms/step - accuracy: 0.7868 - loss: 0.6006 - val_accuracy: 0.7313 - val_loss: 0.8405\n",
      "Epoch 40/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.7902 - loss: 0.6071\n",
      "Epoch 40: val_loss improved from 0.75306 to 0.71536, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 185ms/step - accuracy: 0.7901 - loss: 0.6071 - val_accuracy: 0.7695 - val_loss: 0.7154\n",
      "Epoch 41/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.7834 - loss: 0.6074\n",
      "Epoch 41: val_loss did not improve from 0.71536\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 184ms/step - accuracy: 0.7835 - loss: 0.6073 - val_accuracy: 0.7234 - val_loss: 0.9305\n",
      "Epoch 42/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.7763 - loss: 0.6222\n",
      "Epoch 42: val_loss improved from 0.71536 to 0.70139, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 185ms/step - accuracy: 0.7763 - loss: 0.6221 - val_accuracy: 0.7655 - val_loss: 0.7014\n",
      "Epoch 43/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.7943 - loss: 0.5985\n",
      "Epoch 43: val_loss did not improve from 0.70139\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 186ms/step - accuracy: 0.7943 - loss: 0.5985 - val_accuracy: 0.7218 - val_loss: 0.9801\n",
      "Epoch 44/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.7928 - loss: 0.5777\n",
      "Epoch 44: val_loss did not improve from 0.70139\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 186ms/step - accuracy: 0.7928 - loss: 0.5779 - val_accuracy: 0.7591 - val_loss: 0.7401\n",
      "Epoch 45/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.7851 - loss: 0.5968\n",
      "Epoch 45: val_loss did not improve from 0.70139\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 185ms/step - accuracy: 0.7851 - loss: 0.5968 - val_accuracy: 0.7536 - val_loss: 0.7887\n",
      "Epoch 46/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.7939 - loss: 0.6006\n",
      "Epoch 46: val_loss did not improve from 0.70139\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 191ms/step - accuracy: 0.7939 - loss: 0.6005 - val_accuracy: 0.7583 - val_loss: 0.7816\n",
      "Epoch 47/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.7986 - loss: 0.5800\n",
      "Epoch 47: val_loss did not improve from 0.70139\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 186ms/step - accuracy: 0.7986 - loss: 0.5800 - val_accuracy: 0.7711 - val_loss: 0.7196\n",
      "Epoch 48/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.8060 - loss: 0.5811\n",
      "Epoch 48: val_loss did not improve from 0.70139\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 187ms/step - accuracy: 0.8060 - loss: 0.5811 - val_accuracy: 0.7401 - val_loss: 0.8894\n",
      "Epoch 49/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.7924 - loss: 0.5880\n",
      "Epoch 49: val_loss did not improve from 0.70139\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 187ms/step - accuracy: 0.7925 - loss: 0.5879 - val_accuracy: 0.7655 - val_loss: 0.7814\n",
      "Epoch 50/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.8071 - loss: 0.5609\n",
      "Epoch 50: val_loss did not improve from 0.70139\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 191ms/step - accuracy: 0.8070 - loss: 0.5609 - val_accuracy: 0.7576 - val_loss: 0.7774\n",
      "Epoch 51/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.7991 - loss: 0.5629\n",
      "Epoch 51: val_loss did not improve from 0.70139\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 190ms/step - accuracy: 0.7991 - loss: 0.5630 - val_accuracy: 0.6892 - val_loss: 1.2899\n",
      "Epoch 52/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.8056 - loss: 0.5660\n",
      "Epoch 52: val_loss improved from 0.70139 to 0.69904, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 193ms/step - accuracy: 0.8056 - loss: 0.5659 - val_accuracy: 0.7870 - val_loss: 0.6990\n",
      "Epoch 53/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.8110 - loss: 0.5422\n",
      "Epoch 53: val_loss did not improve from 0.69904\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 192ms/step - accuracy: 0.8110 - loss: 0.5422 - val_accuracy: 0.7599 - val_loss: 0.8185\n",
      "Epoch 54/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.8136 - loss: 0.5397\n",
      "Epoch 54: val_loss did not improve from 0.69904\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 193ms/step - accuracy: 0.8136 - loss: 0.5398 - val_accuracy: 0.7361 - val_loss: 0.9712\n",
      "Epoch 55/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 0.8209 - loss: 0.5348\n",
      "Epoch 55: val_loss did not improve from 0.69904\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 194ms/step - accuracy: 0.8209 - loss: 0.5349 - val_accuracy: 0.7719 - val_loss: 0.7883\n",
      "Epoch 56/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.8274 - loss: 0.5228\n",
      "Epoch 56: val_loss did not improve from 0.69904\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 196ms/step - accuracy: 0.8273 - loss: 0.5229 - val_accuracy: 0.7719 - val_loss: 0.7753\n",
      "Epoch 57/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.8214 - loss: 0.5200\n",
      "Epoch 57: val_loss did not improve from 0.69904\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 194ms/step - accuracy: 0.8213 - loss: 0.5201 - val_accuracy: 0.6638 - val_loss: 1.3147\n",
      "Epoch 58/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.8146 - loss: 0.5304\n",
      "Epoch 58: val_loss did not improve from 0.69904\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 193ms/step - accuracy: 0.8146 - loss: 0.5304 - val_accuracy: 0.7822 - val_loss: 0.7686\n",
      "Epoch 59/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 0.8160 - loss: 0.5307\n",
      "Epoch 59: val_loss improved from 0.69904 to 0.62672, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 195ms/step - accuracy: 0.8160 - loss: 0.5306 - val_accuracy: 0.8084 - val_loss: 0.6267\n",
      "Epoch 60/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.8158 - loss: 0.5430\n",
      "Epoch 60: val_loss did not improve from 0.62672\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 193ms/step - accuracy: 0.8158 - loss: 0.5429 - val_accuracy: 0.7464 - val_loss: 0.9198\n",
      "Epoch 61/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 0.8274 - loss: 0.5030\n",
      "Epoch 61: val_loss did not improve from 0.62672\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 199ms/step - accuracy: 0.8274 - loss: 0.5030 - val_accuracy: 0.7703 - val_loss: 0.7935\n",
      "Epoch 62/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 0.8299 - loss: 0.4920\n",
      "Epoch 62: val_loss did not improve from 0.62672\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 195ms/step - accuracy: 0.8298 - loss: 0.4921 - val_accuracy: 0.7091 - val_loss: 1.1417\n",
      "Epoch 63/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.8348 - loss: 0.4903\n",
      "Epoch 63: val_loss did not improve from 0.62672\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 198ms/step - accuracy: 0.8347 - loss: 0.4904 - val_accuracy: 0.7671 - val_loss: 0.8170\n",
      "Epoch 64/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.8329 - loss: 0.4806\n",
      "Epoch 64: val_loss did not improve from 0.62672\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 197ms/step - accuracy: 0.8328 - loss: 0.4808 - val_accuracy: 0.7417 - val_loss: 0.9647\n",
      "Epoch 65/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.8449 - loss: 0.4660\n",
      "Epoch 65: val_loss did not improve from 0.62672\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 196ms/step - accuracy: 0.8448 - loss: 0.4661 - val_accuracy: 0.7599 - val_loss: 0.8491\n",
      "Epoch 66/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.8284 - loss: 0.4939\n",
      "Epoch 66: val_loss did not improve from 0.62672\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 196ms/step - accuracy: 0.8284 - loss: 0.4940 - val_accuracy: 0.7870 - val_loss: 0.7288\n",
      "Epoch 67/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.8235 - loss: 0.4949\n",
      "Epoch 67: val_loss did not improve from 0.62672\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 196ms/step - accuracy: 0.8235 - loss: 0.4949 - val_accuracy: 0.7424 - val_loss: 1.0157\n",
      "Epoch 68/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 0.8272 - loss: 0.5071\n",
      "Epoch 68: val_loss did not improve from 0.62672\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 195ms/step - accuracy: 0.8272 - loss: 0.5070 - val_accuracy: 0.7750 - val_loss: 0.7924\n",
      "Epoch 69/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8389 - loss: 0.4840\n",
      "Epoch 69: val_loss did not improve from 0.62672\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m331s\u001b[0m 2s/step - accuracy: 0.8389 - loss: 0.4840 - val_accuracy: 0.7830 - val_loss: 0.7221\n",
      "Epoch 70/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.8479 - loss: 0.4559\n",
      "Epoch 70: val_loss did not improve from 0.62672\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 180ms/step - accuracy: 0.8479 - loss: 0.4561 - val_accuracy: 0.7623 - val_loss: 0.8728\n",
      "Epoch 71/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8450 - loss: 0.4696\n",
      "Epoch 71: val_loss did not improve from 0.62672\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m491s\u001b[0m 3s/step - accuracy: 0.8450 - loss: 0.4698 - val_accuracy: 0.7719 - val_loss: 0.7569\n",
      "Epoch 72/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.8413 - loss: 0.4702\n",
      "Epoch 72: val_loss did not improve from 0.62672\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 184ms/step - accuracy: 0.8412 - loss: 0.4702 - val_accuracy: 0.7750 - val_loss: 0.8076\n",
      "Epoch 73/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.8382 - loss: 0.4637\n",
      "Epoch 73: val_loss did not improve from 0.62672\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 183ms/step - accuracy: 0.8382 - loss: 0.4637 - val_accuracy: 0.7639 - val_loss: 0.8920\n",
      "Epoch 74/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.8328 - loss: 0.4847\n",
      "Epoch 74: val_loss did not improve from 0.62672\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 188ms/step - accuracy: 0.8328 - loss: 0.4847 - val_accuracy: 0.7727 - val_loss: 0.7574\n",
      "Epoch 75/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.8332 - loss: 0.4793\n",
      "Epoch 75: val_loss did not improve from 0.62672\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 185ms/step - accuracy: 0.8332 - loss: 0.4793 - val_accuracy: 0.8013 - val_loss: 0.6709\n",
      "Epoch 76/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.8399 - loss: 0.4738\n",
      "Epoch 76: val_loss did not improve from 0.62672\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 185ms/step - accuracy: 0.8399 - loss: 0.4738 - val_accuracy: 0.7997 - val_loss: 0.6551\n",
      "Epoch 77/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.8289 - loss: 0.4886\n",
      "Epoch 77: val_loss did not improve from 0.62672\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 189ms/step - accuracy: 0.8290 - loss: 0.4885 - val_accuracy: 0.7472 - val_loss: 0.9694\n",
      "Epoch 78/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.8403 - loss: 0.4680\n",
      "Epoch 78: val_loss did not improve from 0.62672\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 183ms/step - accuracy: 0.8403 - loss: 0.4680 - val_accuracy: 0.7750 - val_loss: 0.8368\n",
      "Epoch 79/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.8487 - loss: 0.4537\n",
      "Epoch 79: val_loss did not improve from 0.62672\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 182ms/step - accuracy: 0.8487 - loss: 0.4538 - val_accuracy: 0.7901 - val_loss: 0.6913\n",
      "Epoch 80/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.8503 - loss: 0.4303\n",
      "Epoch 80: val_loss did not improve from 0.62672\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 187ms/step - accuracy: 0.8503 - loss: 0.4304 - val_accuracy: 0.7568 - val_loss: 0.8703\n",
      "Epoch 81/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.8411 - loss: 0.4787\n",
      "Epoch 81: val_loss did not improve from 0.62672\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 182ms/step - accuracy: 0.8411 - loss: 0.4786 - val_accuracy: 0.7655 - val_loss: 0.9154\n",
      "Epoch 82/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.8473 - loss: 0.4628\n",
      "Epoch 82: val_loss improved from 0.62672 to 0.57993, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 191ms/step - accuracy: 0.8473 - loss: 0.4627 - val_accuracy: 0.8259 - val_loss: 0.5799\n",
      "Epoch 83/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.8426 - loss: 0.4575\n",
      "Epoch 83: val_loss did not improve from 0.57993\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 183ms/step - accuracy: 0.8426 - loss: 0.4574 - val_accuracy: 0.7893 - val_loss: 0.7197\n",
      "Epoch 84/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.8457 - loss: 0.4467\n",
      "Epoch 84: val_loss did not improve from 0.57993\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 186ms/step - accuracy: 0.8457 - loss: 0.4467 - val_accuracy: 0.7560 - val_loss: 0.9255\n",
      "Epoch 85/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 0.8385 - loss: 0.4631\n",
      "Epoch 85: val_loss did not improve from 0.57993\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 202ms/step - accuracy: 0.8385 - loss: 0.4630 - val_accuracy: 0.7520 - val_loss: 0.9146\n",
      "Epoch 86/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.8497 - loss: 0.4292\n",
      "Epoch 86: val_loss did not improve from 0.57993\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 198ms/step - accuracy: 0.8497 - loss: 0.4292 - val_accuracy: 0.7218 - val_loss: 1.1481\n",
      "Epoch 87/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.8584 - loss: 0.4288\n",
      "Epoch 87: val_loss did not improve from 0.57993\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 188ms/step - accuracy: 0.8583 - loss: 0.4288 - val_accuracy: 0.7838 - val_loss: 0.7721\n",
      "Epoch 88/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.8539 - loss: 0.4396\n",
      "Epoch 88: val_loss improved from 0.57993 to 0.53913, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 188ms/step - accuracy: 0.8539 - loss: 0.4395 - val_accuracy: 0.8307 - val_loss: 0.5391\n",
      "Epoch 89/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.8587 - loss: 0.4155\n",
      "Epoch 89: val_loss did not improve from 0.53913\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 185ms/step - accuracy: 0.8586 - loss: 0.4156 - val_accuracy: 0.7973 - val_loss: 0.6204\n",
      "Epoch 90/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.8367 - loss: 0.4438\n",
      "Epoch 90: val_loss did not improve from 0.53913\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 184ms/step - accuracy: 0.8367 - loss: 0.4437 - val_accuracy: 0.7687 - val_loss: 0.8643\n",
      "Epoch 91/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.8569 - loss: 0.4232\n",
      "Epoch 91: val_loss did not improve from 0.53913\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 185ms/step - accuracy: 0.8569 - loss: 0.4232 - val_accuracy: 0.7734 - val_loss: 0.8301\n",
      "Epoch 92/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.8529 - loss: 0.4265\n",
      "Epoch 92: val_loss did not improve from 0.53913\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 185ms/step - accuracy: 0.8529 - loss: 0.4265 - val_accuracy: 0.7846 - val_loss: 0.7684\n",
      "Epoch 93/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.8512 - loss: 0.4431\n",
      "Epoch 93: val_loss did not improve from 0.53913\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 187ms/step - accuracy: 0.8512 - loss: 0.4430 - val_accuracy: 0.7925 - val_loss: 0.7297\n",
      "Epoch 94/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.8567 - loss: 0.4173\n",
      "Epoch 94: val_loss did not improve from 0.53913\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 187ms/step - accuracy: 0.8567 - loss: 0.4173 - val_accuracy: 0.7011 - val_loss: 1.3775\n",
      "Epoch 95/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 0.8653 - loss: 0.3942\n",
      "Epoch 95: val_loss did not improve from 0.53913\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 201ms/step - accuracy: 0.8652 - loss: 0.3943 - val_accuracy: 0.7528 - val_loss: 1.1959\n",
      "Epoch 96/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - accuracy: 0.8631 - loss: 0.4200\n",
      "Epoch 96: val_loss did not improve from 0.53913\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 200ms/step - accuracy: 0.8631 - loss: 0.4199 - val_accuracy: 0.7591 - val_loss: 0.8510\n",
      "Epoch 97/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.8592 - loss: 0.4184\n",
      "Epoch 97: val_loss did not improve from 0.53913\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 184ms/step - accuracy: 0.8592 - loss: 0.4183 - val_accuracy: 0.8188 - val_loss: 0.5971\n",
      "Epoch 98/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.8603 - loss: 0.4157\n",
      "Epoch 98: val_loss did not improve from 0.53913\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 187ms/step - accuracy: 0.8604 - loss: 0.4157 - val_accuracy: 0.7687 - val_loss: 0.8998\n",
      "Epoch 99/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.8758 - loss: 0.3904\n",
      "Epoch 99: val_loss did not improve from 0.53913\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 185ms/step - accuracy: 0.8758 - loss: 0.3906 - val_accuracy: 0.7901 - val_loss: 0.7610\n",
      "Epoch 100/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.8681 - loss: 0.3969\n",
      "Epoch 100: val_loss did not improve from 0.53913\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 184ms/step - accuracy: 0.8681 - loss: 0.3970 - val_accuracy: 0.8092 - val_loss: 0.6419\n",
      "Epoch 101/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.8614 - loss: 0.3892\n",
      "Epoch 101: val_loss did not improve from 0.53913\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 188ms/step - accuracy: 0.8614 - loss: 0.3893 - val_accuracy: 0.7973 - val_loss: 0.7144\n",
      "Epoch 102/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.8608 - loss: 0.3914\n",
      "Epoch 102: val_loss did not improve from 0.53913\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 188ms/step - accuracy: 0.8608 - loss: 0.3915 - val_accuracy: 0.8243 - val_loss: 0.5602\n",
      "Epoch 103/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.8560 - loss: 0.4192\n",
      "Epoch 103: val_loss did not improve from 0.53913\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 185ms/step - accuracy: 0.8561 - loss: 0.4190 - val_accuracy: 0.7536 - val_loss: 1.0170\n",
      "Epoch 104/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.8666 - loss: 0.3962\n",
      "Epoch 104: val_loss did not improve from 0.53913\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 187ms/step - accuracy: 0.8666 - loss: 0.3962 - val_accuracy: 0.7973 - val_loss: 0.6748\n",
      "Epoch 105/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.8792 - loss: 0.3693\n",
      "Epoch 105: val_loss did not improve from 0.53913\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 186ms/step - accuracy: 0.8792 - loss: 0.3694 - val_accuracy: 0.8132 - val_loss: 0.6739\n",
      "Epoch 106/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.8742 - loss: 0.3819\n",
      "Epoch 106: val_loss did not improve from 0.53913\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 191ms/step - accuracy: 0.8742 - loss: 0.3819 - val_accuracy: 0.7401 - val_loss: 1.0325\n",
      "Epoch 107/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 0.8690 - loss: 0.3868\n",
      "Epoch 107: val_loss did not improve from 0.53913\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 205ms/step - accuracy: 0.8690 - loss: 0.3867 - val_accuracy: 0.7838 - val_loss: 0.8499\n",
      "Epoch 108/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 0.8806 - loss: 0.3766\n",
      "Epoch 108: val_loss did not improve from 0.53913\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 214ms/step - accuracy: 0.8806 - loss: 0.3765 - val_accuracy: 0.7671 - val_loss: 0.9543\n",
      "Epoch 109/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 0.8621 - loss: 0.4026\n",
      "Epoch 109: val_loss did not improve from 0.53913\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 204ms/step - accuracy: 0.8622 - loss: 0.4025 - val_accuracy: 0.7114 - val_loss: 1.4190\n",
      "Epoch 110/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 0.8651 - loss: 0.4013\n",
      "Epoch 110: val_loss did not improve from 0.53913\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 206ms/step - accuracy: 0.8651 - loss: 0.4012 - val_accuracy: 0.7734 - val_loss: 0.8472\n",
      "Epoch 111/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.8764 - loss: 0.3794\n",
      "Epoch 111: val_loss did not improve from 0.53913\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 223ms/step - accuracy: 0.8763 - loss: 0.3794 - val_accuracy: 0.7846 - val_loss: 0.7937\n",
      "Epoch 112/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 0.8671 - loss: 0.3951\n",
      "Epoch 112: val_loss did not improve from 0.53913\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 205ms/step - accuracy: 0.8671 - loss: 0.3950 - val_accuracy: 0.6836 - val_loss: 1.6897\n",
      "Epoch 113/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 0.8655 - loss: 0.3945\n",
      "Epoch 113: val_loss did not improve from 0.53913\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 206ms/step - accuracy: 0.8655 - loss: 0.3945 - val_accuracy: 0.8029 - val_loss: 0.7284\n",
      "Epoch 114/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 0.8652 - loss: 0.3950\n",
      "Epoch 114: val_loss did not improve from 0.53913\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 204ms/step - accuracy: 0.8653 - loss: 0.3950 - val_accuracy: 0.8076 - val_loss: 0.7029\n",
      "Epoch 115/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - accuracy: 0.8804 - loss: 0.3679\n",
      "Epoch 115: val_loss did not improve from 0.53913\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 210ms/step - accuracy: 0.8804 - loss: 0.3680 - val_accuracy: 0.7893 - val_loss: 0.8002\n",
      "Epoch 116/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 0.8783 - loss: 0.3654\n",
      "Epoch 116: val_loss did not improve from 0.53913\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 205ms/step - accuracy: 0.8783 - loss: 0.3655 - val_accuracy: 0.7671 - val_loss: 0.9185\n",
      "Epoch 117/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 0.8796 - loss: 0.3617\n",
      "Epoch 117: val_loss did not improve from 0.53913\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 216ms/step - accuracy: 0.8796 - loss: 0.3618 - val_accuracy: 0.8196 - val_loss: 0.6213\n",
      "Epoch 118/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.8810 - loss: 0.3651\n",
      "Epoch 118: val_loss did not improve from 0.53913\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 213ms/step - accuracy: 0.8810 - loss: 0.3651 - val_accuracy: 0.7917 - val_loss: 0.7837\n",
      "Epoch 119/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - accuracy: 0.8758 - loss: 0.3601\n",
      "Epoch 119: val_loss did not improve from 0.53913\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 210ms/step - accuracy: 0.8758 - loss: 0.3601 - val_accuracy: 0.8164 - val_loss: 0.6158\n",
      "Epoch 120/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 0.8848 - loss: 0.3426\n",
      "Epoch 120: val_loss did not improve from 0.53913\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 206ms/step - accuracy: 0.8848 - loss: 0.3426 - val_accuracy: 0.7170 - val_loss: 1.5943\n",
      "Epoch 121/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.8681 - loss: 0.3837\n",
      "Epoch 121: val_loss did not improve from 0.53913\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 212ms/step - accuracy: 0.8682 - loss: 0.3837 - val_accuracy: 0.7703 - val_loss: 0.9005\n",
      "Epoch 122/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 0.8746 - loss: 0.3532\n",
      "Epoch 122: val_loss did not improve from 0.53913\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 212ms/step - accuracy: 0.8746 - loss: 0.3532 - val_accuracy: 0.7941 - val_loss: 0.7736\n",
      "Epoch 123/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - accuracy: 0.8862 - loss: 0.3486\n",
      "Epoch 123: val_loss did not improve from 0.53913\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 211ms/step - accuracy: 0.8862 - loss: 0.3486 - val_accuracy: 0.8243 - val_loss: 0.6243\n",
      "Epoch 124/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.8790 - loss: 0.3600\n",
      "Epoch 124: val_loss did not improve from 0.53913\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 217ms/step - accuracy: 0.8790 - loss: 0.3600 - val_accuracy: 0.7568 - val_loss: 1.2317\n",
      "Epoch 125/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.8768 - loss: 0.3749\n",
      "Epoch 125: val_loss did not improve from 0.53913\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 199ms/step - accuracy: 0.8769 - loss: 0.3748 - val_accuracy: 0.7774 - val_loss: 0.9538\n",
      "Epoch 126/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.8840 - loss: 0.3568\n",
      "Epoch 126: val_loss did not improve from 0.53913\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 198ms/step - accuracy: 0.8840 - loss: 0.3568 - val_accuracy: 0.8052 - val_loss: 0.6945\n",
      "Epoch 127/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.8902 - loss: 0.3359\n",
      "Epoch 127: val_loss did not improve from 0.53913\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 198ms/step - accuracy: 0.8902 - loss: 0.3360 - val_accuracy: 0.8362 - val_loss: 0.5441\n",
      "Epoch 128/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.8872 - loss: 0.3505\n",
      "Epoch 128: val_loss did not improve from 0.53913\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 198ms/step - accuracy: 0.8872 - loss: 0.3505 - val_accuracy: 0.7790 - val_loss: 0.8361\n",
      "Epoch 129/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.8869 - loss: 0.3398\n",
      "Epoch 129: val_loss did not improve from 0.53913\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 197ms/step - accuracy: 0.8869 - loss: 0.3399 - val_accuracy: 0.7083 - val_loss: 1.4943\n",
      "Epoch 130/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 0.8923 - loss: 0.3409\n",
      "Epoch 130: val_loss did not improve from 0.53913\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 201ms/step - accuracy: 0.8923 - loss: 0.3409 - val_accuracy: 0.7997 - val_loss: 0.7237\n",
      "Epoch 131/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 0.8817 - loss: 0.3490\n",
      "Epoch 131: val_loss did not improve from 0.53913\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 202ms/step - accuracy: 0.8817 - loss: 0.3490 - val_accuracy: 0.7695 - val_loss: 1.0149\n",
      "Epoch 132/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 0.8882 - loss: 0.3391\n",
      "Epoch 132: val_loss did not improve from 0.53913\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 199ms/step - accuracy: 0.8882 - loss: 0.3391 - val_accuracy: 0.7901 - val_loss: 0.8517\n",
      "Epoch 133/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.8867 - loss: 0.3431\n",
      "Epoch 133: val_loss did not improve from 0.53913\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 199ms/step - accuracy: 0.8867 - loss: 0.3430 - val_accuracy: 0.8339 - val_loss: 0.5806\n",
      "Epoch 134/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8862 - loss: 0.3387\n",
      "Epoch 134: val_loss did not improve from 0.53913\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m513s\u001b[0m 3s/step - accuracy: 0.8862 - loss: 0.3387 - val_accuracy: 0.8347 - val_loss: 0.5628\n",
      "Epoch 135/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.8889 - loss: 0.3312\n",
      "Epoch 135: val_loss did not improve from 0.53913\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 180ms/step - accuracy: 0.8889 - loss: 0.3313 - val_accuracy: 0.7925 - val_loss: 0.7649\n",
      "Epoch 136/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.8896 - loss: 0.3428\n",
      "Epoch 136: val_loss did not improve from 0.53913\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m733s\u001b[0m 5s/step - accuracy: 0.8897 - loss: 0.3427 - val_accuracy: 0.8243 - val_loss: 0.6350\n",
      "Epoch 137/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.8966 - loss: 0.3081\n",
      "Epoch 137: val_loss did not improve from 0.53913\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 182ms/step - accuracy: 0.8966 - loss: 0.3082 - val_accuracy: 0.7599 - val_loss: 1.1212\n",
      "Epoch 138/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.8873 - loss: 0.3326\n",
      "Epoch 138: val_loss did not improve from 0.53913\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 182ms/step - accuracy: 0.8874 - loss: 0.3326 - val_accuracy: 0.7027 - val_loss: 1.5453\n",
      "Epoch 139/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.8941 - loss: 0.3330\n",
      "Epoch 139: val_loss did not improve from 0.53913\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 182ms/step - accuracy: 0.8941 - loss: 0.3330 - val_accuracy: 0.7742 - val_loss: 1.0937\n",
      "Epoch 140/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.8897 - loss: 0.3180\n",
      "Epoch 140: val_loss improved from 0.53913 to 0.53338, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 183ms/step - accuracy: 0.8896 - loss: 0.3181 - val_accuracy: 0.8410 - val_loss: 0.5334\n",
      "Epoch 141/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.8863 - loss: 0.3340\n",
      "Epoch 141: val_loss improved from 0.53338 to 0.50273, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 185ms/step - accuracy: 0.8863 - loss: 0.3339 - val_accuracy: 0.8434 - val_loss: 0.5027\n",
      "Epoch 142/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.8853 - loss: 0.3362\n",
      "Epoch 142: val_loss did not improve from 0.50273\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 181ms/step - accuracy: 0.8853 - loss: 0.3361 - val_accuracy: 0.7703 - val_loss: 0.9698\n",
      "Epoch 143/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.8867 - loss: 0.3415\n",
      "Epoch 143: val_loss did not improve from 0.50273\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 182ms/step - accuracy: 0.8867 - loss: 0.3415 - val_accuracy: 0.8124 - val_loss: 0.7056\n",
      "Epoch 144/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.9008 - loss: 0.3046\n",
      "Epoch 144: val_loss did not improve from 0.50273\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 182ms/step - accuracy: 0.9008 - loss: 0.3047 - val_accuracy: 0.7917 - val_loss: 0.8145\n",
      "Epoch 145/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.8996 - loss: 0.3271\n",
      "Epoch 145: val_loss did not improve from 0.50273\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 182ms/step - accuracy: 0.8995 - loss: 0.3271 - val_accuracy: 0.7830 - val_loss: 0.9330\n",
      "Epoch 146/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9022 - loss: 0.3145\n",
      "Epoch 146: val_loss did not improve from 0.50273\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 192ms/step - accuracy: 0.9021 - loss: 0.3146 - val_accuracy: 0.8267 - val_loss: 0.5885\n",
      "Epoch 147/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.8967 - loss: 0.3088\n",
      "Epoch 147: val_loss did not improve from 0.50273\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 187ms/step - accuracy: 0.8967 - loss: 0.3089 - val_accuracy: 0.7671 - val_loss: 1.0113\n",
      "Epoch 148/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.9117 - loss: 0.2845\n",
      "Epoch 148: val_loss did not improve from 0.50273\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 183ms/step - accuracy: 0.9116 - loss: 0.2847 - val_accuracy: 0.8124 - val_loss: 0.7013\n",
      "Epoch 149/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.8984 - loss: 0.3056\n",
      "Epoch 149: val_loss did not improve from 0.50273\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 192ms/step - accuracy: 0.8984 - loss: 0.3055 - val_accuracy: 0.7854 - val_loss: 0.8336\n",
      "Epoch 150/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.8891 - loss: 0.3143\n",
      "Epoch 150: val_loss did not improve from 0.50273\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 192ms/step - accuracy: 0.8892 - loss: 0.3143 - val_accuracy: 0.7011 - val_loss: 1.5231\n",
      "Epoch 151/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.8914 - loss: 0.3253\n",
      "Epoch 151: val_loss did not improve from 0.50273\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 187ms/step - accuracy: 0.8915 - loss: 0.3253 - val_accuracy: 0.7965 - val_loss: 0.8260\n",
      "Epoch 152/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9016 - loss: 0.3050\n",
      "Epoch 152: val_loss did not improve from 0.50273\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 191ms/step - accuracy: 0.9016 - loss: 0.3050 - val_accuracy: 0.7520 - val_loss: 1.1946\n",
      "Epoch 153/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.8972 - loss: 0.3139\n",
      "Epoch 153: val_loss did not improve from 0.50273\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 187ms/step - accuracy: 0.8972 - loss: 0.3138 - val_accuracy: 0.8060 - val_loss: 0.6820\n",
      "Epoch 154/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.8981 - loss: 0.3143\n",
      "Epoch 154: val_loss did not improve from 0.50273\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 187ms/step - accuracy: 0.8982 - loss: 0.3142 - val_accuracy: 0.8045 - val_loss: 0.7383\n",
      "Epoch 155/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.9002 - loss: 0.2989\n",
      "Epoch 155: val_loss did not improve from 0.50273\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 184ms/step - accuracy: 0.9002 - loss: 0.2990 - val_accuracy: 0.8108 - val_loss: 0.7424\n",
      "Epoch 156/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9052 - loss: 0.2973\n",
      "Epoch 156: val_loss did not improve from 0.50273\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 189ms/step - accuracy: 0.9051 - loss: 0.2973 - val_accuracy: 0.7671 - val_loss: 1.1017\n",
      "Epoch 157/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9109 - loss: 0.2780\n",
      "Epoch 157: val_loss did not improve from 0.50273\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 190ms/step - accuracy: 0.9109 - loss: 0.2781 - val_accuracy: 0.8124 - val_loss: 0.7087\n",
      "Epoch 158/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.8990 - loss: 0.3122\n",
      "Epoch 158: val_loss did not improve from 0.50273\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 191ms/step - accuracy: 0.8991 - loss: 0.3120 - val_accuracy: 0.8188 - val_loss: 0.6923\n",
      "Epoch 159/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.9001 - loss: 0.3205\n",
      "Epoch 159: val_loss did not improve from 0.50273\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 196ms/step - accuracy: 0.9001 - loss: 0.3205 - val_accuracy: 0.7965 - val_loss: 0.8199\n",
      "Epoch 160/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 0.8978 - loss: 0.3128\n",
      "Epoch 160: val_loss did not improve from 0.50273\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 201ms/step - accuracy: 0.8978 - loss: 0.3127 - val_accuracy: 0.7766 - val_loss: 0.9373\n",
      "Epoch 161/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 0.8983 - loss: 0.3149\n",
      "Epoch 161: val_loss did not improve from 0.50273\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 195ms/step - accuracy: 0.8983 - loss: 0.3149 - val_accuracy: 0.7758 - val_loss: 0.9788\n",
      "Epoch 162/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.8981 - loss: 0.3153\n",
      "Epoch 162: val_loss did not improve from 0.50273\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 195ms/step - accuracy: 0.8981 - loss: 0.3152 - val_accuracy: 0.8243 - val_loss: 0.6414\n",
      "Epoch 163/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.8953 - loss: 0.3073\n",
      "Epoch 163: val_loss did not improve from 0.50273\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 190ms/step - accuracy: 0.8953 - loss: 0.3072 - val_accuracy: 0.8227 - val_loss: 0.7131\n",
      "Epoch 164/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.9076 - loss: 0.2855\n",
      "Epoch 164: val_loss did not improve from 0.50273\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 195ms/step - accuracy: 0.9075 - loss: 0.2855 - val_accuracy: 0.8068 - val_loss: 0.8149\n",
      "Epoch 165/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9072 - loss: 0.2907\n",
      "Epoch 165: val_loss did not improve from 0.50273\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 190ms/step - accuracy: 0.9072 - loss: 0.2907 - val_accuracy: 0.8132 - val_loss: 0.7111\n",
      "Epoch 166/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.9062 - loss: 0.2923\n",
      "Epoch 166: val_loss did not improve from 0.50273\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 197ms/step - accuracy: 0.9062 - loss: 0.2922 - val_accuracy: 0.7909 - val_loss: 0.7893\n",
      "Epoch 167/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 0.9002 - loss: 0.2917\n",
      "Epoch 167: val_loss did not improve from 0.50273\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 200ms/step - accuracy: 0.9002 - loss: 0.2916 - val_accuracy: 0.7909 - val_loss: 0.9651\n",
      "Epoch 168/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.9047 - loss: 0.2935\n",
      "Epoch 168: val_loss did not improve from 0.50273\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 198ms/step - accuracy: 0.9048 - loss: 0.2935 - val_accuracy: 0.7734 - val_loss: 1.0505\n",
      "Epoch 169/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.9096 - loss: 0.2864\n",
      "Epoch 169: val_loss did not improve from 0.50273\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 196ms/step - accuracy: 0.9096 - loss: 0.2864 - val_accuracy: 0.8259 - val_loss: 0.6744\n",
      "Epoch 170/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.9070 - loss: 0.2813\n",
      "Epoch 170: val_loss did not improve from 0.50273\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 197ms/step - accuracy: 0.9070 - loss: 0.2813 - val_accuracy: 0.8172 - val_loss: 0.6829\n",
      "Epoch 171/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.9115 - loss: 0.2782\n",
      "Epoch 171: val_loss did not improve from 0.50273\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 193ms/step - accuracy: 0.9115 - loss: 0.2782 - val_accuracy: 0.7989 - val_loss: 0.8664\n",
      "Epoch 172/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - accuracy: 0.9046 - loss: 0.2735\n",
      "Epoch 172: val_loss did not improve from 0.50273\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 208ms/step - accuracy: 0.9046 - loss: 0.2735 - val_accuracy: 0.8466 - val_loss: 0.5110\n",
      "Epoch 173/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.9125 - loss: 0.2708\n",
      "Epoch 173: val_loss did not improve from 0.50273\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 213ms/step - accuracy: 0.9125 - loss: 0.2709 - val_accuracy: 0.8291 - val_loss: 0.5871\n",
      "Epoch 174/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 0.9123 - loss: 0.2715\n",
      "Epoch 174: val_loss did not improve from 0.50273\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 203ms/step - accuracy: 0.9123 - loss: 0.2716 - val_accuracy: 0.7583 - val_loss: 1.1825\n",
      "Epoch 175/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9146 - loss: 0.2549\n",
      "Epoch 175: val_loss did not improve from 0.50273\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 189ms/step - accuracy: 0.9146 - loss: 0.2550 - val_accuracy: 0.7432 - val_loss: 1.3871\n",
      "Epoch 176/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.9115 - loss: 0.2720\n",
      "Epoch 176: val_loss did not improve from 0.50273\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 188ms/step - accuracy: 0.9116 - loss: 0.2720 - val_accuracy: 0.7878 - val_loss: 0.8708\n",
      "Epoch 177/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.9102 - loss: 0.2720\n",
      "Epoch 177: val_loss did not improve from 0.50273\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 195ms/step - accuracy: 0.9103 - loss: 0.2721 - val_accuracy: 0.7456 - val_loss: 1.4005\n",
      "Epoch 178/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 0.9122 - loss: 0.2600\n",
      "Epoch 178: val_loss did not improve from 0.50273\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 217ms/step - accuracy: 0.9122 - loss: 0.2600 - val_accuracy: 0.6773 - val_loss: 2.0895\n",
      "Epoch 179/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 0.9089 - loss: 0.2842\n",
      "Epoch 179: val_loss did not improve from 0.50273\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 203ms/step - accuracy: 0.9089 - loss: 0.2842 - val_accuracy: 0.8442 - val_loss: 0.5566\n",
      "Epoch 180/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.9144 - loss: 0.2637\n",
      "Epoch 180: val_loss did not improve from 0.50273\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 193ms/step - accuracy: 0.9144 - loss: 0.2637 - val_accuracy: 0.7727 - val_loss: 1.1056\n",
      "Epoch 181/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.9213 - loss: 0.2482\n",
      "Epoch 181: val_loss did not improve from 0.50273\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 195ms/step - accuracy: 0.9212 - loss: 0.2482 - val_accuracy: 0.8211 - val_loss: 0.6659\n",
      "Epoch 182/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 0.9206 - loss: 0.2515\n",
      "Epoch 182: val_loss did not improve from 0.50273\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 202ms/step - accuracy: 0.9206 - loss: 0.2516 - val_accuracy: 0.8029 - val_loss: 0.7763\n",
      "Epoch 183/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.9062 - loss: 0.2792\n",
      "Epoch 183: val_loss did not improve from 0.50273\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 195ms/step - accuracy: 0.9062 - loss: 0.2792 - val_accuracy: 0.7695 - val_loss: 1.0805\n",
      "Epoch 184/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.9168 - loss: 0.2635\n",
      "Epoch 184: val_loss did not improve from 0.50273\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 197ms/step - accuracy: 0.9168 - loss: 0.2636 - val_accuracy: 0.8108 - val_loss: 0.7433\n",
      "Epoch 185/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 0.9110 - loss: 0.2773\n",
      "Epoch 185: val_loss did not improve from 0.50273\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 202ms/step - accuracy: 0.9110 - loss: 0.2773 - val_accuracy: 0.7909 - val_loss: 0.9430\n",
      "Epoch 186/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9153 - loss: 0.2627\n",
      "Epoch 186: val_loss did not improve from 0.50273\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 191ms/step - accuracy: 0.9153 - loss: 0.2627 - val_accuracy: 0.8259 - val_loss: 0.6886\n",
      "Epoch 187/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9082 - loss: 0.2673\n",
      "Epoch 187: val_loss improved from 0.50273 to 0.49748, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 192ms/step - accuracy: 0.9082 - loss: 0.2672 - val_accuracy: 0.8553 - val_loss: 0.4975\n",
      "Epoch 188/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9264 - loss: 0.2417\n",
      "Epoch 188: val_loss did not improve from 0.49748\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 190ms/step - accuracy: 0.9263 - loss: 0.2418 - val_accuracy: 0.8203 - val_loss: 0.7439\n",
      "Epoch 189/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9202 - loss: 0.2526\n",
      "Epoch 189: val_loss did not improve from 0.49748\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 191ms/step - accuracy: 0.9202 - loss: 0.2527 - val_accuracy: 0.8514 - val_loss: 0.5391\n",
      "Epoch 190/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 0.9119 - loss: 0.2592\n",
      "Epoch 190: val_loss did not improve from 0.49748\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 201ms/step - accuracy: 0.9119 - loss: 0.2592 - val_accuracy: 0.7886 - val_loss: 1.0284\n",
      "Epoch 191/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9114 - loss: 0.2684\n",
      "Epoch 191: val_loss did not improve from 0.49748\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 192ms/step - accuracy: 0.9114 - loss: 0.2683 - val_accuracy: 0.8203 - val_loss: 0.7205\n",
      "Epoch 192/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.9173 - loss: 0.2466\n",
      "Epoch 192: val_loss did not improve from 0.49748\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 196ms/step - accuracy: 0.9173 - loss: 0.2466 - val_accuracy: 0.8339 - val_loss: 0.6453\n",
      "Epoch 193/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.9067 - loss: 0.2692\n",
      "Epoch 193: val_loss improved from 0.49748 to 0.48740, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 197ms/step - accuracy: 0.9067 - loss: 0.2691 - val_accuracy: 0.8593 - val_loss: 0.4874\n",
      "Epoch 194/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 0.9155 - loss: 0.2509\n",
      "Epoch 194: val_loss did not improve from 0.48740\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 211ms/step - accuracy: 0.9155 - loss: 0.2509 - val_accuracy: 0.8450 - val_loss: 0.5770\n",
      "Epoch 195/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.9141 - loss: 0.2508\n",
      "Epoch 195: val_loss did not improve from 0.48740\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 199ms/step - accuracy: 0.9141 - loss: 0.2508 - val_accuracy: 0.8331 - val_loss: 0.6274\n",
      "Epoch 196/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.9156 - loss: 0.2586\n",
      "Epoch 196: val_loss did not improve from 0.48740\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 196ms/step - accuracy: 0.9156 - loss: 0.2585 - val_accuracy: 0.8052 - val_loss: 0.7936\n",
      "Epoch 197/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9207 - loss: 0.2427\n",
      "Epoch 197: val_loss did not improve from 0.48740\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 191ms/step - accuracy: 0.9207 - loss: 0.2426 - val_accuracy: 0.8529 - val_loss: 0.5441\n",
      "Epoch 198/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.9194 - loss: 0.2450\n",
      "Epoch 198: val_loss did not improve from 0.48740\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 193ms/step - accuracy: 0.9194 - loss: 0.2450 - val_accuracy: 0.8553 - val_loss: 0.5185\n",
      "Epoch 199/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9228 - loss: 0.2357\n",
      "Epoch 199: val_loss did not improve from 0.48740\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 193ms/step - accuracy: 0.9228 - loss: 0.2358 - val_accuracy: 0.8037 - val_loss: 0.8450\n",
      "Epoch 200/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 0.9223 - loss: 0.2300\n",
      "Epoch 200: val_loss did not improve from 0.48740\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 196ms/step - accuracy: 0.9222 - loss: 0.2301 - val_accuracy: 0.8577 - val_loss: 0.5092\n",
      "Epoch 201/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.9163 - loss: 0.2406\n",
      "Epoch 201: val_loss did not improve from 0.48740\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 197ms/step - accuracy: 0.9163 - loss: 0.2406 - val_accuracy: 0.8148 - val_loss: 0.7554\n",
      "Epoch 202/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 0.9239 - loss: 0.2416\n",
      "Epoch 202: val_loss did not improve from 0.48740\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 208ms/step - accuracy: 0.9238 - loss: 0.2417 - val_accuracy: 0.8275 - val_loss: 0.6695\n",
      "Epoch 203/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - accuracy: 0.9253 - loss: 0.2381\n",
      "Epoch 203: val_loss did not improve from 0.48740\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 221ms/step - accuracy: 0.9252 - loss: 0.2381 - val_accuracy: 0.7989 - val_loss: 0.9462\n",
      "Epoch 204/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.9243 - loss: 0.2311\n",
      "Epoch 204: val_loss did not improve from 0.48740\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 213ms/step - accuracy: 0.9243 - loss: 0.2313 - val_accuracy: 0.6614 - val_loss: 2.4854\n",
      "Epoch 205/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - accuracy: 0.9138 - loss: 0.2556\n",
      "Epoch 205: val_loss did not improve from 0.48740\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 200ms/step - accuracy: 0.9138 - loss: 0.2557 - val_accuracy: 0.8108 - val_loss: 0.7304\n",
      "Epoch 206/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 0.9265 - loss: 0.2413\n",
      "Epoch 206: val_loss did not improve from 0.48740\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 204ms/step - accuracy: 0.9264 - loss: 0.2413 - val_accuracy: 0.7893 - val_loss: 0.9767\n",
      "Epoch 207/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - accuracy: 0.9264 - loss: 0.2314\n",
      "Epoch 207: val_loss did not improve from 0.48740\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 207ms/step - accuracy: 0.9264 - loss: 0.2314 - val_accuracy: 0.8307 - val_loss: 0.6262\n",
      "Epoch 208/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 0.9210 - loss: 0.2333\n",
      "Epoch 208: val_loss did not improve from 0.48740\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 206ms/step - accuracy: 0.9210 - loss: 0.2333 - val_accuracy: 0.8410 - val_loss: 0.6263\n",
      "Epoch 209/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.9221 - loss: 0.2346\n",
      "Epoch 209: val_loss did not improve from 0.48740\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 198ms/step - accuracy: 0.9221 - loss: 0.2346 - val_accuracy: 0.8434 - val_loss: 0.5665\n",
      "Epoch 210/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 0.9183 - loss: 0.2418\n",
      "Epoch 210: val_loss did not improve from 0.48740\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 205ms/step - accuracy: 0.9183 - loss: 0.2418 - val_accuracy: 0.8052 - val_loss: 0.8655\n",
      "Epoch 211/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 0.9253 - loss: 0.2307\n",
      "Epoch 211: val_loss did not improve from 0.48740\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 199ms/step - accuracy: 0.9253 - loss: 0.2307 - val_accuracy: 0.7297 - val_loss: 1.4137\n",
      "Epoch 212/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.9254 - loss: 0.2251\n",
      "Epoch 212: val_loss did not improve from 0.48740\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 199ms/step - accuracy: 0.9254 - loss: 0.2251 - val_accuracy: 0.8474 - val_loss: 0.5542\n",
      "Epoch 213/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.9314 - loss: 0.2206\n",
      "Epoch 213: val_loss did not improve from 0.48740\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 218ms/step - accuracy: 0.9314 - loss: 0.2206 - val_accuracy: 0.7075 - val_loss: 1.6439\n",
      "Epoch 214/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 0.9150 - loss: 0.2418\n",
      "Epoch 214: val_loss did not improve from 0.48740\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 208ms/step - accuracy: 0.9150 - loss: 0.2417 - val_accuracy: 0.8386 - val_loss: 0.5790\n",
      "Epoch 215/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 0.9181 - loss: 0.2424\n",
      "Epoch 215: val_loss did not improve from 0.48740\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 213ms/step - accuracy: 0.9182 - loss: 0.2424 - val_accuracy: 0.7989 - val_loss: 0.8749\n",
      "Epoch 216/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 0.9315 - loss: 0.2142\n",
      "Epoch 216: val_loss did not improve from 0.48740\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 200ms/step - accuracy: 0.9315 - loss: 0.2142 - val_accuracy: 0.7703 - val_loss: 1.0533\n",
      "Epoch 217/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.9205 - loss: 0.2357\n",
      "Epoch 217: val_loss did not improve from 0.48740\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 220ms/step - accuracy: 0.9205 - loss: 0.2357 - val_accuracy: 0.7878 - val_loss: 0.9752\n",
      "Epoch 218/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.9320 - loss: 0.2158\n",
      "Epoch 218: val_loss improved from 0.48740 to 0.47597, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 214ms/step - accuracy: 0.9319 - loss: 0.2158 - val_accuracy: 0.8601 - val_loss: 0.4760\n",
      "Epoch 219/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.9252 - loss: 0.2338\n",
      "Epoch 219: val_loss did not improve from 0.47597\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 212ms/step - accuracy: 0.9252 - loss: 0.2338 - val_accuracy: 0.7893 - val_loss: 1.0148\n",
      "Epoch 220/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - accuracy: 0.9297 - loss: 0.2305\n",
      "Epoch 220: val_loss did not improve from 0.47597\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 202ms/step - accuracy: 0.9297 - loss: 0.2304 - val_accuracy: 0.8521 - val_loss: 0.5348\n",
      "Epoch 221/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 0.9212 - loss: 0.2165\n",
      "Epoch 221: val_loss did not improve from 0.47597\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 206ms/step - accuracy: 0.9213 - loss: 0.2165 - val_accuracy: 0.8498 - val_loss: 0.5642\n",
      "Epoch 222/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.9189 - loss: 0.2382\n",
      "Epoch 222: val_loss did not improve from 0.47597\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 217ms/step - accuracy: 0.9190 - loss: 0.2381 - val_accuracy: 0.8045 - val_loss: 0.9173\n",
      "Epoch 223/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.9309 - loss: 0.2171\n",
      "Epoch 223: val_loss did not improve from 0.47597\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 199ms/step - accuracy: 0.9309 - loss: 0.2172 - val_accuracy: 0.8267 - val_loss: 0.6868\n",
      "Epoch 224/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.9293 - loss: 0.2225\n",
      "Epoch 224: val_loss improved from 0.47597 to 0.46089, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 212ms/step - accuracy: 0.9293 - loss: 0.2225 - val_accuracy: 0.8577 - val_loss: 0.4609\n",
      "Epoch 225/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - accuracy: 0.9310 - loss: 0.2185\n",
      "Epoch 225: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 210ms/step - accuracy: 0.9310 - loss: 0.2185 - val_accuracy: 0.8219 - val_loss: 0.7729\n",
      "Epoch 226/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.9292 - loss: 0.2099\n",
      "Epoch 226: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 212ms/step - accuracy: 0.9293 - loss: 0.2099 - val_accuracy: 0.8585 - val_loss: 0.4972\n",
      "Epoch 227/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.9273 - loss: 0.2185\n",
      "Epoch 227: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 198ms/step - accuracy: 0.9273 - loss: 0.2185 - val_accuracy: 0.8339 - val_loss: 0.6276\n",
      "Epoch 228/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 0.9334 - loss: 0.2158\n",
      "Epoch 228: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 201ms/step - accuracy: 0.9334 - loss: 0.2158 - val_accuracy: 0.8545 - val_loss: 0.5646\n",
      "Epoch 229/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 0.9321 - loss: 0.2171\n",
      "Epoch 229: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 194ms/step - accuracy: 0.9321 - loss: 0.2171 - val_accuracy: 0.7997 - val_loss: 0.9125\n",
      "Epoch 230/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 0.9334 - loss: 0.2103\n",
      "Epoch 230: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 201ms/step - accuracy: 0.9334 - loss: 0.2104 - val_accuracy: 0.7925 - val_loss: 0.9082\n",
      "Epoch 231/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - accuracy: 0.9225 - loss: 0.2216\n",
      "Epoch 231: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 208ms/step - accuracy: 0.9225 - loss: 0.2216 - val_accuracy: 0.8529 - val_loss: 0.5410\n",
      "Epoch 232/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - accuracy: 0.9334 - loss: 0.2161\n",
      "Epoch 232: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 209ms/step - accuracy: 0.9334 - loss: 0.2160 - val_accuracy: 0.7981 - val_loss: 0.8799\n",
      "Epoch 233/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.9321 - loss: 0.2056\n",
      "Epoch 233: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 220ms/step - accuracy: 0.9321 - loss: 0.2056 - val_accuracy: 0.7202 - val_loss: 2.0580\n",
      "Epoch 234/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - accuracy: 0.9253 - loss: 0.2259\n",
      "Epoch 234: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 202ms/step - accuracy: 0.9253 - loss: 0.2258 - val_accuracy: 0.8545 - val_loss: 0.5444\n",
      "Epoch 235/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 0.9281 - loss: 0.2076\n",
      "Epoch 235: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 201ms/step - accuracy: 0.9282 - loss: 0.2076 - val_accuracy: 0.8426 - val_loss: 0.6378\n",
      "Epoch 236/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 0.9328 - loss: 0.2067\n",
      "Epoch 236: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 205ms/step - accuracy: 0.9327 - loss: 0.2067 - val_accuracy: 0.8164 - val_loss: 0.8082\n",
      "Epoch 237/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 0.9323 - loss: 0.2008\n",
      "Epoch 237: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 205ms/step - accuracy: 0.9323 - loss: 0.2008 - val_accuracy: 0.7933 - val_loss: 0.9503\n",
      "Epoch 238/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 0.9350 - loss: 0.1973\n",
      "Epoch 238: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 201ms/step - accuracy: 0.9350 - loss: 0.1974 - val_accuracy: 0.7242 - val_loss: 1.5500\n",
      "Epoch 239/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.9215 - loss: 0.2311\n",
      "Epoch 239: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 214ms/step - accuracy: 0.9216 - loss: 0.2310 - val_accuracy: 0.8490 - val_loss: 0.6261\n",
      "Epoch 240/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 0.9355 - loss: 0.1968\n",
      "Epoch 240: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 201ms/step - accuracy: 0.9355 - loss: 0.1968 - val_accuracy: 0.8196 - val_loss: 0.7792\n",
      "Epoch 241/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 0.9348 - loss: 0.1993\n",
      "Epoch 241: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 207ms/step - accuracy: 0.9348 - loss: 0.1993 - val_accuracy: 0.8291 - val_loss: 0.6692\n",
      "Epoch 242/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.9355 - loss: 0.2084\n",
      "Epoch 242: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 227ms/step - accuracy: 0.9355 - loss: 0.2085 - val_accuracy: 0.8164 - val_loss: 0.8042\n",
      "Epoch 243/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.9285 - loss: 0.2092\n",
      "Epoch 243: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 218ms/step - accuracy: 0.9285 - loss: 0.2092 - val_accuracy: 0.7226 - val_loss: 1.8735\n",
      "Epoch 244/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.9362 - loss: 0.1997\n",
      "Epoch 244: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 222ms/step - accuracy: 0.9362 - loss: 0.1997 - val_accuracy: 0.8633 - val_loss: 0.4808\n",
      "Epoch 245/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.9373 - loss: 0.2020\n",
      "Epoch 245: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 220ms/step - accuracy: 0.9373 - loss: 0.2020 - val_accuracy: 0.7854 - val_loss: 0.8027\n",
      "Epoch 246/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.9265 - loss: 0.2185\n",
      "Epoch 246: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 198ms/step - accuracy: 0.9266 - loss: 0.2184 - val_accuracy: 0.7870 - val_loss: 1.0758\n",
      "Epoch 247/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.9360 - loss: 0.2029\n",
      "Epoch 247: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 214ms/step - accuracy: 0.9360 - loss: 0.2030 - val_accuracy: 0.8402 - val_loss: 0.6331\n",
      "Epoch 248/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.9446 - loss: 0.1890\n",
      "Epoch 248: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 216ms/step - accuracy: 0.9446 - loss: 0.1890 - val_accuracy: 0.8633 - val_loss: 0.4644\n",
      "Epoch 249/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 0.9295 - loss: 0.2111\n",
      "Epoch 249: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 200ms/step - accuracy: 0.9295 - loss: 0.2110 - val_accuracy: 0.7655 - val_loss: 1.4479\n",
      "Epoch 250/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - accuracy: 0.9340 - loss: 0.2040\n",
      "Epoch 250: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 209ms/step - accuracy: 0.9341 - loss: 0.2040 - val_accuracy: 0.7369 - val_loss: 1.4749\n",
      "Epoch 251/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 0.9377 - loss: 0.1909\n",
      "Epoch 251: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 202ms/step - accuracy: 0.9376 - loss: 0.1910 - val_accuracy: 0.7798 - val_loss: 1.1136\n",
      "Epoch 252/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.9409 - loss: 0.1790\n",
      "Epoch 252: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 197ms/step - accuracy: 0.9409 - loss: 0.1792 - val_accuracy: 0.5358 - val_loss: 6.6575\n",
      "Epoch 253/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 0.9276 - loss: 0.2281\n",
      "Epoch 253: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 195ms/step - accuracy: 0.9276 - loss: 0.2280 - val_accuracy: 0.7488 - val_loss: 1.4798\n",
      "Epoch 254/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 0.9479 - loss: 0.1703\n",
      "Epoch 254: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 205ms/step - accuracy: 0.9478 - loss: 0.1704 - val_accuracy: 0.8180 - val_loss: 0.8526\n",
      "Epoch 255/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 0.9349 - loss: 0.1964\n",
      "Epoch 255: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 216ms/step - accuracy: 0.9349 - loss: 0.1964 - val_accuracy: 0.8410 - val_loss: 0.7010\n",
      "Epoch 256/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - accuracy: 0.9431 - loss: 0.1780\n",
      "Epoch 256: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 201ms/step - accuracy: 0.9430 - loss: 0.1780 - val_accuracy: 0.8617 - val_loss: 0.5405\n",
      "Epoch 257/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.9355 - loss: 0.1910\n",
      "Epoch 257: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 214ms/step - accuracy: 0.9355 - loss: 0.1910 - val_accuracy: 0.8378 - val_loss: 0.6723\n",
      "Epoch 258/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - accuracy: 0.9282 - loss: 0.2211\n",
      "Epoch 258: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 210ms/step - accuracy: 0.9283 - loss: 0.2210 - val_accuracy: 0.7655 - val_loss: 1.4168\n",
      "Epoch 259/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.9389 - loss: 0.1875\n",
      "Epoch 259: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 213ms/step - accuracy: 0.9389 - loss: 0.1876 - val_accuracy: 0.8386 - val_loss: 0.6805\n",
      "Epoch 260/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - accuracy: 0.9326 - loss: 0.1994\n",
      "Epoch 260: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 201ms/step - accuracy: 0.9326 - loss: 0.1994 - val_accuracy: 0.8506 - val_loss: 0.6289\n",
      "Epoch 261/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9395 - loss: 0.1898\n",
      "Epoch 261: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 190ms/step - accuracy: 0.9395 - loss: 0.1898 - val_accuracy: 0.8625 - val_loss: 0.5208\n",
      "Epoch 262/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.9311 - loss: 0.2050\n",
      "Epoch 262: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 197ms/step - accuracy: 0.9312 - loss: 0.2050 - val_accuracy: 0.7798 - val_loss: 1.4606\n",
      "Epoch 263/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.9349 - loss: 0.2048\n",
      "Epoch 263: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 200ms/step - accuracy: 0.9349 - loss: 0.2047 - val_accuracy: 0.8370 - val_loss: 0.6121\n",
      "Epoch 264/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 0.9373 - loss: 0.1913\n",
      "Epoch 264: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 202ms/step - accuracy: 0.9373 - loss: 0.1912 - val_accuracy: 0.7742 - val_loss: 1.2005\n",
      "Epoch 265/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 0.9365 - loss: 0.1993\n",
      "Epoch 265: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 205ms/step - accuracy: 0.9365 - loss: 0.1992 - val_accuracy: 0.7472 - val_loss: 1.5640\n",
      "Epoch 266/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - accuracy: 0.9385 - loss: 0.1885\n",
      "Epoch 266: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 213ms/step - accuracy: 0.9385 - loss: 0.1885 - val_accuracy: 0.8084 - val_loss: 0.8734\n",
      "Epoch 267/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - accuracy: 0.9408 - loss: 0.1856\n",
      "Epoch 267: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 211ms/step - accuracy: 0.9408 - loss: 0.1856 - val_accuracy: 0.6908 - val_loss: 1.9910\n",
      "Epoch 268/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.9399 - loss: 0.1945\n",
      "Epoch 268: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 225ms/step - accuracy: 0.9399 - loss: 0.1945 - val_accuracy: 0.8490 - val_loss: 0.6035\n",
      "Epoch 269/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 0.9440 - loss: 0.1782\n",
      "Epoch 269: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 204ms/step - accuracy: 0.9440 - loss: 0.1783 - val_accuracy: 0.8283 - val_loss: 0.7345\n",
      "Epoch 270/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.9364 - loss: 0.1908\n",
      "Epoch 270: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 221ms/step - accuracy: 0.9364 - loss: 0.1908 - val_accuracy: 0.7583 - val_loss: 1.3525\n",
      "Epoch 271/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 0.9370 - loss: 0.1952\n",
      "Epoch 271: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 203ms/step - accuracy: 0.9370 - loss: 0.1952 - val_accuracy: 0.8203 - val_loss: 0.8205\n",
      "Epoch 272/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 0.9402 - loss: 0.1786\n",
      "Epoch 272: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 205ms/step - accuracy: 0.9402 - loss: 0.1786 - val_accuracy: 0.6789 - val_loss: 2.0978\n",
      "Epoch 273/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 0.9486 - loss: 0.1729\n",
      "Epoch 273: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 201ms/step - accuracy: 0.9486 - loss: 0.1729 - val_accuracy: 0.8323 - val_loss: 0.7139\n",
      "Epoch 274/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 0.9465 - loss: 0.1740\n",
      "Epoch 274: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 205ms/step - accuracy: 0.9465 - loss: 0.1740 - val_accuracy: 0.8355 - val_loss: 0.6622\n",
      "Epoch 275/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step - accuracy: 0.9436 - loss: 0.1725\n",
      "Epoch 275: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 249ms/step - accuracy: 0.9435 - loss: 0.1725 - val_accuracy: 0.8394 - val_loss: 0.5484\n",
      "Epoch 276/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.9379 - loss: 0.1864\n",
      "Epoch 276: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 217ms/step - accuracy: 0.9380 - loss: 0.1863 - val_accuracy: 0.8704 - val_loss: 0.5025\n",
      "Epoch 277/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - accuracy: 0.9429 - loss: 0.1832\n",
      "Epoch 277: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 207ms/step - accuracy: 0.9429 - loss: 0.1832 - val_accuracy: 0.8498 - val_loss: 0.6654\n",
      "Epoch 278/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 0.9392 - loss: 0.1860\n",
      "Epoch 278: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 204ms/step - accuracy: 0.9392 - loss: 0.1860 - val_accuracy: 0.8116 - val_loss: 0.9232\n",
      "Epoch 279/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - accuracy: 0.9455 - loss: 0.1720\n",
      "Epoch 279: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 209ms/step - accuracy: 0.9455 - loss: 0.1720 - val_accuracy: 0.8251 - val_loss: 0.7840\n",
      "Epoch 280/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - accuracy: 0.9455 - loss: 0.1716\n",
      "Epoch 280: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 210ms/step - accuracy: 0.9455 - loss: 0.1717 - val_accuracy: 0.7297 - val_loss: 1.4722\n",
      "Epoch 281/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 0.9422 - loss: 0.1714\n",
      "Epoch 281: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 203ms/step - accuracy: 0.9421 - loss: 0.1715 - val_accuracy: 0.8482 - val_loss: 0.6339\n",
      "Epoch 282/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 0.9474 - loss: 0.1716\n",
      "Epoch 282: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 199ms/step - accuracy: 0.9474 - loss: 0.1716 - val_accuracy: 0.8235 - val_loss: 0.7902\n",
      "Epoch 283/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 0.9392 - loss: 0.1776\n",
      "Epoch 283: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 200ms/step - accuracy: 0.9392 - loss: 0.1776 - val_accuracy: 0.7909 - val_loss: 1.0989\n",
      "Epoch 284/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - accuracy: 0.9500 - loss: 0.1673\n",
      "Epoch 284: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 200ms/step - accuracy: 0.9500 - loss: 0.1674 - val_accuracy: 0.8585 - val_loss: 0.5408\n",
      "Epoch 285/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 0.9424 - loss: 0.1742\n",
      "Epoch 285: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 202ms/step - accuracy: 0.9424 - loss: 0.1743 - val_accuracy: 0.7838 - val_loss: 1.3168\n",
      "Epoch 286/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 0.9450 - loss: 0.1624\n",
      "Epoch 286: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 202ms/step - accuracy: 0.9450 - loss: 0.1624 - val_accuracy: 0.8609 - val_loss: 0.4966\n",
      "Epoch 287/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 0.9419 - loss: 0.1798\n",
      "Epoch 287: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 202ms/step - accuracy: 0.9419 - loss: 0.1797 - val_accuracy: 0.8323 - val_loss: 0.7562\n",
      "Epoch 288/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 0.9464 - loss: 0.1651\n",
      "Epoch 288: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 203ms/step - accuracy: 0.9464 - loss: 0.1652 - val_accuracy: 0.8211 - val_loss: 0.8769\n",
      "Epoch 289/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.9510 - loss: 0.1533\n",
      "Epoch 289: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 219ms/step - accuracy: 0.9509 - loss: 0.1535 - val_accuracy: 0.7949 - val_loss: 1.0307\n",
      "Epoch 290/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 0.9482 - loss: 0.1729\n",
      "Epoch 290: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 226ms/step - accuracy: 0.9482 - loss: 0.1729 - val_accuracy: 0.8498 - val_loss: 0.6102\n",
      "Epoch 291/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - accuracy: 0.9437 - loss: 0.1650\n",
      "Epoch 291: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 201ms/step - accuracy: 0.9437 - loss: 0.1650 - val_accuracy: 0.8601 - val_loss: 0.5657\n",
      "Epoch 292/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 0.9447 - loss: 0.1600\n",
      "Epoch 292: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 206ms/step - accuracy: 0.9447 - loss: 0.1600 - val_accuracy: 0.8243 - val_loss: 0.8240\n",
      "Epoch 293/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.9481 - loss: 0.1647\n",
      "Epoch 293: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 231ms/step - accuracy: 0.9481 - loss: 0.1647 - val_accuracy: 0.8132 - val_loss: 0.9473\n",
      "Epoch 294/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.9514 - loss: 0.1550\n",
      "Epoch 294: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 218ms/step - accuracy: 0.9514 - loss: 0.1550 - val_accuracy: 0.7909 - val_loss: 0.9806\n",
      "Epoch 295/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 0.9457 - loss: 0.1673\n",
      "Epoch 295: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 207ms/step - accuracy: 0.9457 - loss: 0.1673 - val_accuracy: 0.8696 - val_loss: 0.4768\n",
      "Epoch 296/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.9486 - loss: 0.1593\n",
      "Epoch 296: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 199ms/step - accuracy: 0.9486 - loss: 0.1593 - val_accuracy: 0.7917 - val_loss: 1.1111\n",
      "Epoch 297/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.9469 - loss: 0.1625\n",
      "Epoch 297: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 198ms/step - accuracy: 0.9469 - loss: 0.1625 - val_accuracy: 0.8633 - val_loss: 0.5265\n",
      "Epoch 298/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 0.9451 - loss: 0.1583\n",
      "Epoch 298: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 199ms/step - accuracy: 0.9451 - loss: 0.1584 - val_accuracy: 0.8219 - val_loss: 0.7724\n",
      "Epoch 299/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - accuracy: 0.9547 - loss: 0.1472\n",
      "Epoch 299: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 207ms/step - accuracy: 0.9546 - loss: 0.1473 - val_accuracy: 0.7782 - val_loss: 1.2162\n",
      "Epoch 300/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - accuracy: 0.9531 - loss: 0.1461\n",
      "Epoch 300: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 210ms/step - accuracy: 0.9531 - loss: 0.1461 - val_accuracy: 0.7758 - val_loss: 1.5263\n",
      "Epoch 301/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - accuracy: 0.9428 - loss: 0.1815\n",
      "Epoch 301: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 210ms/step - accuracy: 0.9428 - loss: 0.1814 - val_accuracy: 0.8696 - val_loss: 0.5219\n",
      "Epoch 302/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 0.9492 - loss: 0.1522\n",
      "Epoch 302: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 201ms/step - accuracy: 0.9492 - loss: 0.1523 - val_accuracy: 0.8060 - val_loss: 0.9050\n",
      "Epoch 303/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - accuracy: 0.9476 - loss: 0.1660\n",
      "Epoch 303: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 208ms/step - accuracy: 0.9476 - loss: 0.1659 - val_accuracy: 0.8267 - val_loss: 0.7181\n",
      "Epoch 304/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.9442 - loss: 0.1586\n",
      "Epoch 304: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 214ms/step - accuracy: 0.9442 - loss: 0.1587 - val_accuracy: 0.8196 - val_loss: 0.8071\n",
      "Epoch 305/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 0.9505 - loss: 0.1579\n",
      "Epoch 305: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 216ms/step - accuracy: 0.9505 - loss: 0.1579 - val_accuracy: 0.7981 - val_loss: 1.0879\n",
      "Epoch 306/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 0.9510 - loss: 0.1568\n",
      "Epoch 306: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 203ms/step - accuracy: 0.9510 - loss: 0.1569 - val_accuracy: 0.8243 - val_loss: 0.7871\n",
      "Epoch 307/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 0.9535 - loss: 0.1467\n",
      "Epoch 307: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 202ms/step - accuracy: 0.9535 - loss: 0.1467 - val_accuracy: 0.8132 - val_loss: 0.8895\n",
      "Epoch 308/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.9456 - loss: 0.1636\n",
      "Epoch 308: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 215ms/step - accuracy: 0.9456 - loss: 0.1637 - val_accuracy: 0.8386 - val_loss: 0.7044\n",
      "Epoch 309/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.9454 - loss: 0.1537\n",
      "Epoch 309: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 197ms/step - accuracy: 0.9454 - loss: 0.1537 - val_accuracy: 0.7711 - val_loss: 1.2323\n",
      "Epoch 310/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9531 - loss: 0.1418\n",
      "Epoch 310: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 192ms/step - accuracy: 0.9531 - loss: 0.1419 - val_accuracy: 0.8355 - val_loss: 0.7207\n",
      "Epoch 311/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9544 - loss: 0.1531\n",
      "Epoch 311: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 192ms/step - accuracy: 0.9544 - loss: 0.1531 - val_accuracy: 0.7893 - val_loss: 1.0930\n",
      "Epoch 312/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9458 - loss: 0.1680\n",
      "Epoch 312: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 191ms/step - accuracy: 0.9458 - loss: 0.1680 - val_accuracy: 0.7170 - val_loss: 2.1546\n",
      "Epoch 313/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9465 - loss: 0.1592\n",
      "Epoch 313: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 191ms/step - accuracy: 0.9465 - loss: 0.1592 - val_accuracy: 0.7663 - val_loss: 1.3956\n",
      "Epoch 314/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9476 - loss: 0.1641\n",
      "Epoch 314: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 192ms/step - accuracy: 0.9476 - loss: 0.1640 - val_accuracy: 0.7973 - val_loss: 1.0646\n",
      "Epoch 315/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.9521 - loss: 0.1604\n",
      "Epoch 315: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 193ms/step - accuracy: 0.9521 - loss: 0.1604 - val_accuracy: 0.8307 - val_loss: 0.7438\n",
      "Epoch 316/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9495 - loss: 0.1601\n",
      "Epoch 316: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 192ms/step - accuracy: 0.9496 - loss: 0.1600 - val_accuracy: 0.8498 - val_loss: 0.6567\n",
      "Epoch 317/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.9485 - loss: 0.1561\n",
      "Epoch 317: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 193ms/step - accuracy: 0.9485 - loss: 0.1561 - val_accuracy: 0.7933 - val_loss: 1.0772\n",
      "Epoch 318/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.9536 - loss: 0.1430\n",
      "Epoch 318: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 193ms/step - accuracy: 0.9536 - loss: 0.1430 - val_accuracy: 0.8052 - val_loss: 1.0311\n",
      "Epoch 319/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.9431 - loss: 0.1675\n",
      "Epoch 319: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 196ms/step - accuracy: 0.9432 - loss: 0.1674 - val_accuracy: 0.8688 - val_loss: 0.4787\n",
      "Epoch 320/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 0.9547 - loss: 0.1414\n",
      "Epoch 320: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 216ms/step - accuracy: 0.9547 - loss: 0.1415 - val_accuracy: 0.8140 - val_loss: 0.9660\n",
      "Epoch 321/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 0.9517 - loss: 0.1470\n",
      "Epoch 321: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 203ms/step - accuracy: 0.9517 - loss: 0.1470 - val_accuracy: 0.8068 - val_loss: 0.9424\n",
      "Epoch 322/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 0.9521 - loss: 0.1494\n",
      "Epoch 322: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 204ms/step - accuracy: 0.9521 - loss: 0.1494 - val_accuracy: 0.6153 - val_loss: 3.5727\n",
      "Epoch 323/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - accuracy: 0.9487 - loss: 0.1575\n",
      "Epoch 323: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 200ms/step - accuracy: 0.9487 - loss: 0.1575 - val_accuracy: 0.8434 - val_loss: 0.6685\n",
      "Epoch 324/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9545 - loss: 0.1491\n",
      "Epoch 324: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 193ms/step - accuracy: 0.9545 - loss: 0.1490 - val_accuracy: 0.8649 - val_loss: 0.4936\n",
      "Epoch 325/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9489 - loss: 0.1533\n",
      "Epoch 325: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 193ms/step - accuracy: 0.9489 - loss: 0.1533 - val_accuracy: 0.7901 - val_loss: 1.0864\n",
      "Epoch 326/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.9517 - loss: 0.1539\n",
      "Epoch 326: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 196ms/step - accuracy: 0.9517 - loss: 0.1539 - val_accuracy: 0.8529 - val_loss: 0.5473\n",
      "Epoch 327/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9539 - loss: 0.1445\n",
      "Epoch 327: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 192ms/step - accuracy: 0.9539 - loss: 0.1446 - val_accuracy: 0.8331 - val_loss: 0.7574\n",
      "Epoch 328/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 0.9569 - loss: 0.1409\n",
      "Epoch 328: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 194ms/step - accuracy: 0.9568 - loss: 0.1410 - val_accuracy: 0.8339 - val_loss: 0.7378\n",
      "Epoch 329/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 0.9488 - loss: 0.1660\n",
      "Epoch 329: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 195ms/step - accuracy: 0.9488 - loss: 0.1659 - val_accuracy: 0.8466 - val_loss: 0.6552\n",
      "Epoch 330/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.9591 - loss: 0.1394\n",
      "Epoch 330: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 193ms/step - accuracy: 0.9591 - loss: 0.1394 - val_accuracy: 0.8283 - val_loss: 0.7779\n",
      "Epoch 331/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.9543 - loss: 0.1413\n",
      "Epoch 331: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 193ms/step - accuracy: 0.9543 - loss: 0.1414 - val_accuracy: 0.8569 - val_loss: 0.5712\n",
      "Epoch 332/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9542 - loss: 0.1489\n",
      "Epoch 332: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 193ms/step - accuracy: 0.9542 - loss: 0.1489 - val_accuracy: 0.8633 - val_loss: 0.4933\n",
      "Epoch 333/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9544 - loss: 0.1489\n",
      "Epoch 333: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 191ms/step - accuracy: 0.9545 - loss: 0.1489 - val_accuracy: 0.8529 - val_loss: 0.6280\n",
      "Epoch 334/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9563 - loss: 0.1448\n",
      "Epoch 334: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 192ms/step - accuracy: 0.9563 - loss: 0.1448 - val_accuracy: 0.8378 - val_loss: 0.7094\n",
      "Epoch 335/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.9569 - loss: 0.1389\n",
      "Epoch 335: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 194ms/step - accuracy: 0.9569 - loss: 0.1389 - val_accuracy: 0.7544 - val_loss: 1.6568\n",
      "Epoch 336/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 0.9562 - loss: 0.1458\n",
      "Epoch 336: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 194ms/step - accuracy: 0.9562 - loss: 0.1458 - val_accuracy: 0.8108 - val_loss: 0.9449\n",
      "Epoch 337/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - accuracy: 0.9542 - loss: 0.1453\n",
      "Epoch 337: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 210ms/step - accuracy: 0.9542 - loss: 0.1452 - val_accuracy: 0.7520 - val_loss: 1.5736\n",
      "Epoch 338/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 0.9524 - loss: 0.1436\n",
      "Epoch 338: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 203ms/step - accuracy: 0.9524 - loss: 0.1436 - val_accuracy: 0.8569 - val_loss: 0.5472\n",
      "Epoch 339/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.9611 - loss: 0.1370\n",
      "Epoch 339: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 199ms/step - accuracy: 0.9610 - loss: 0.1370 - val_accuracy: 0.8514 - val_loss: 0.5874\n",
      "Epoch 340/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.9536 - loss: 0.1434\n",
      "Epoch 340: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 197ms/step - accuracy: 0.9536 - loss: 0.1434 - val_accuracy: 0.8402 - val_loss: 0.6819\n",
      "Epoch 341/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - accuracy: 0.9537 - loss: 0.1411\n",
      "Epoch 341: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 201ms/step - accuracy: 0.9537 - loss: 0.1411 - val_accuracy: 0.8196 - val_loss: 0.8781\n",
      "Epoch 342/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.9604 - loss: 0.1338\n",
      "Epoch 342: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 195ms/step - accuracy: 0.9603 - loss: 0.1338 - val_accuracy: 0.8529 - val_loss: 0.6427\n",
      "Epoch 343/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 0.9641 - loss: 0.1310\n",
      "Epoch 343: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 203ms/step - accuracy: 0.9640 - loss: 0.1310 - val_accuracy: 0.8378 - val_loss: 0.7800\n",
      "Epoch 344/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.9530 - loss: 0.1436\n",
      "Epoch 344: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 197ms/step - accuracy: 0.9531 - loss: 0.1435 - val_accuracy: 0.7361 - val_loss: 1.8344\n",
      "Epoch 345/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9420 - loss: 0.1812\n",
      "Epoch 345: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 191ms/step - accuracy: 0.9421 - loss: 0.1810 - val_accuracy: 0.8498 - val_loss: 0.6624\n",
      "Epoch 346/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9556 - loss: 0.1459\n",
      "Epoch 346: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 191ms/step - accuracy: 0.9556 - loss: 0.1459 - val_accuracy: 0.8196 - val_loss: 0.8341\n",
      "Epoch 347/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9577 - loss: 0.1367\n",
      "Epoch 347: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 191ms/step - accuracy: 0.9577 - loss: 0.1368 - val_accuracy: 0.8347 - val_loss: 0.7232\n",
      "Epoch 348/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9527 - loss: 0.1523\n",
      "Epoch 348: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 191ms/step - accuracy: 0.9527 - loss: 0.1522 - val_accuracy: 0.8434 - val_loss: 0.6845\n",
      "Epoch 349/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.9489 - loss: 0.1501\n",
      "Epoch 349: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 193ms/step - accuracy: 0.9490 - loss: 0.1501 - val_accuracy: 0.7385 - val_loss: 1.7111\n",
      "Epoch 350/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9601 - loss: 0.1356\n",
      "Epoch 350: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 192ms/step - accuracy: 0.9601 - loss: 0.1356 - val_accuracy: 0.8275 - val_loss: 0.7720\n",
      "Epoch 351/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9542 - loss: 0.1378\n",
      "Epoch 351: val_loss did not improve from 0.46089\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 193ms/step - accuracy: 0.9542 - loss: 0.1377 - val_accuracy: 0.7965 - val_loss: 0.9600\n",
      "Epoch 352/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9620 - loss: 0.1243\n",
      "Epoch 352: val_loss improved from 0.46089 to 0.44107, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 191ms/step - accuracy: 0.9620 - loss: 0.1243 - val_accuracy: 0.8744 - val_loss: 0.4411\n",
      "Epoch 353/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9558 - loss: 0.1320\n",
      "Epoch 353: val_loss did not improve from 0.44107\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 191ms/step - accuracy: 0.9558 - loss: 0.1320 - val_accuracy: 0.8037 - val_loss: 1.0333\n",
      "Epoch 354/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9564 - loss: 0.1402\n",
      "Epoch 354: val_loss did not improve from 0.44107\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 189ms/step - accuracy: 0.9564 - loss: 0.1401 - val_accuracy: 0.8394 - val_loss: 0.6975\n",
      "Epoch 355/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9582 - loss: 0.1287\n",
      "Epoch 355: val_loss did not improve from 0.44107\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 189ms/step - accuracy: 0.9582 - loss: 0.1287 - val_accuracy: 0.8625 - val_loss: 0.5874\n",
      "Epoch 356/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9534 - loss: 0.1397\n",
      "Epoch 356: val_loss did not improve from 0.44107\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 189ms/step - accuracy: 0.9535 - loss: 0.1397 - val_accuracy: 0.8482 - val_loss: 0.6275\n",
      "Epoch 357/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.9608 - loss: 0.1236\n",
      "Epoch 357: val_loss did not improve from 0.44107\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 199ms/step - accuracy: 0.9608 - loss: 0.1237 - val_accuracy: 0.8521 - val_loss: 0.6216\n",
      "Epoch 358/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 0.9580 - loss: 0.1266\n",
      "Epoch 358: val_loss did not improve from 0.44107\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 208ms/step - accuracy: 0.9580 - loss: 0.1266 - val_accuracy: 0.8076 - val_loss: 1.0654\n",
      "Epoch 359/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 0.9625 - loss: 0.1202\n",
      "Epoch 359: val_loss did not improve from 0.44107\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 206ms/step - accuracy: 0.9624 - loss: 0.1203 - val_accuracy: 0.8696 - val_loss: 0.4940\n",
      "Epoch 360/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.9591 - loss: 0.1475\n",
      "Epoch 360: val_loss did not improve from 0.44107\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 199ms/step - accuracy: 0.9591 - loss: 0.1475 - val_accuracy: 0.8156 - val_loss: 0.9746\n",
      "Epoch 361/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9543 - loss: 0.1420\n",
      "Epoch 361: val_loss did not improve from 0.44107\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 193ms/step - accuracy: 0.9544 - loss: 0.1420 - val_accuracy: 0.8196 - val_loss: 0.8607\n",
      "Epoch 362/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9584 - loss: 0.1384\n",
      "Epoch 362: val_loss did not improve from 0.44107\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 191ms/step - accuracy: 0.9584 - loss: 0.1384 - val_accuracy: 0.7933 - val_loss: 1.1587\n",
      "Epoch 363/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9624 - loss: 0.1196\n",
      "Epoch 363: val_loss did not improve from 0.44107\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 192ms/step - accuracy: 0.9624 - loss: 0.1196 - val_accuracy: 0.8180 - val_loss: 0.9571\n",
      "Epoch 364/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9611 - loss: 0.1220\n",
      "Epoch 364: val_loss did not improve from 0.44107\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 189ms/step - accuracy: 0.9611 - loss: 0.1220 - val_accuracy: 0.8370 - val_loss: 0.7733\n",
      "Epoch 365/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9537 - loss: 0.1421\n",
      "Epoch 365: val_loss did not improve from 0.44107\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 191ms/step - accuracy: 0.9537 - loss: 0.1421 - val_accuracy: 0.8426 - val_loss: 0.6660\n",
      "Epoch 366/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9574 - loss: 0.1330\n",
      "Epoch 366: val_loss did not improve from 0.44107\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 191ms/step - accuracy: 0.9574 - loss: 0.1330 - val_accuracy: 0.8323 - val_loss: 0.8671\n",
      "Epoch 367/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9645 - loss: 0.1202\n",
      "Epoch 367: val_loss did not improve from 0.44107\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 192ms/step - accuracy: 0.9645 - loss: 0.1202 - val_accuracy: 0.7194 - val_loss: 2.0766\n",
      "Epoch 368/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9646 - loss: 0.1143\n",
      "Epoch 368: val_loss did not improve from 0.44107\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 191ms/step - accuracy: 0.9646 - loss: 0.1144 - val_accuracy: 0.8172 - val_loss: 0.8628\n",
      "Epoch 369/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9626 - loss: 0.1267\n",
      "Epoch 369: val_loss improved from 0.44107 to 0.40098, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 192ms/step - accuracy: 0.9626 - loss: 0.1267 - val_accuracy: 0.8855 - val_loss: 0.4010\n",
      "Epoch 370/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.9641 - loss: 0.1209\n",
      "Epoch 370: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 197ms/step - accuracy: 0.9641 - loss: 0.1210 - val_accuracy: 0.8736 - val_loss: 0.4834\n",
      "Epoch 371/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9533 - loss: 0.1385\n",
      "Epoch 371: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 192ms/step - accuracy: 0.9533 - loss: 0.1385 - val_accuracy: 0.8410 - val_loss: 0.7056\n",
      "Epoch 372/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9588 - loss: 0.1293\n",
      "Epoch 372: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 191ms/step - accuracy: 0.9588 - loss: 0.1293 - val_accuracy: 0.8180 - val_loss: 0.9367\n",
      "Epoch 373/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.9620 - loss: 0.1220\n",
      "Epoch 373: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 195ms/step - accuracy: 0.9620 - loss: 0.1220 - val_accuracy: 0.8752 - val_loss: 0.4574\n",
      "Epoch 374/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 0.9668 - loss: 0.1199\n",
      "Epoch 374: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 195ms/step - accuracy: 0.9668 - loss: 0.1200 - val_accuracy: 0.8736 - val_loss: 0.4901\n",
      "Epoch 375/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.9617 - loss: 0.1253\n",
      "Epoch 375: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 194ms/step - accuracy: 0.9617 - loss: 0.1253 - val_accuracy: 0.8243 - val_loss: 0.9106\n",
      "Epoch 376/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.9595 - loss: 0.1300\n",
      "Epoch 376: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 194ms/step - accuracy: 0.9595 - loss: 0.1299 - val_accuracy: 0.7949 - val_loss: 1.2726\n",
      "Epoch 377/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 0.9608 - loss: 0.1268\n",
      "Epoch 377: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 194ms/step - accuracy: 0.9608 - loss: 0.1267 - val_accuracy: 0.8537 - val_loss: 0.6061\n",
      "Epoch 378/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.9644 - loss: 0.1246\n",
      "Epoch 378: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 196ms/step - accuracy: 0.9644 - loss: 0.1246 - val_accuracy: 0.7925 - val_loss: 1.0759\n",
      "Epoch 379/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.9687 - loss: 0.1145\n",
      "Epoch 379: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 195ms/step - accuracy: 0.9687 - loss: 0.1145 - val_accuracy: 0.8307 - val_loss: 0.7425\n",
      "Epoch 380/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.9619 - loss: 0.1264\n",
      "Epoch 380: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 198ms/step - accuracy: 0.9619 - loss: 0.1264 - val_accuracy: 0.8307 - val_loss: 0.8061\n",
      "Epoch 381/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.9674 - loss: 0.1074\n",
      "Epoch 381: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 197ms/step - accuracy: 0.9674 - loss: 0.1075 - val_accuracy: 0.8808 - val_loss: 0.4465\n",
      "Epoch 382/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.9582 - loss: 0.1277\n",
      "Epoch 382: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 196ms/step - accuracy: 0.9582 - loss: 0.1276 - val_accuracy: 0.8315 - val_loss: 0.7734\n",
      "Epoch 383/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.9559 - loss: 0.1331\n",
      "Epoch 383: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 193ms/step - accuracy: 0.9559 - loss: 0.1330 - val_accuracy: 0.8180 - val_loss: 0.8973\n",
      "Epoch 384/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.9681 - loss: 0.1082\n",
      "Epoch 384: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 197ms/step - accuracy: 0.9681 - loss: 0.1082 - val_accuracy: 0.8370 - val_loss: 0.7511\n",
      "Epoch 385/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9676 - loss: 0.1132\n",
      "Epoch 385: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 191ms/step - accuracy: 0.9675 - loss: 0.1132 - val_accuracy: 0.8203 - val_loss: 0.8623\n",
      "Epoch 386/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.9639 - loss: 0.1189\n",
      "Epoch 386: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 193ms/step - accuracy: 0.9639 - loss: 0.1189 - val_accuracy: 0.8402 - val_loss: 0.7067\n",
      "Epoch 387/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.9641 - loss: 0.1156\n",
      "Epoch 387: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 194ms/step - accuracy: 0.9640 - loss: 0.1156 - val_accuracy: 0.8323 - val_loss: 0.8032\n",
      "Epoch 388/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 0.9672 - loss: 0.1100\n",
      "Epoch 388: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 194ms/step - accuracy: 0.9672 - loss: 0.1100 - val_accuracy: 0.6979 - val_loss: 2.1324\n",
      "Epoch 389/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 0.9543 - loss: 0.1403\n",
      "Epoch 389: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 195ms/step - accuracy: 0.9543 - loss: 0.1402 - val_accuracy: 0.8474 - val_loss: 0.7144\n",
      "Epoch 390/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.9606 - loss: 0.1332\n",
      "Epoch 390: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 199ms/step - accuracy: 0.9606 - loss: 0.1332 - val_accuracy: 0.8450 - val_loss: 0.6851\n",
      "Epoch 391/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.9596 - loss: 0.1311\n",
      "Epoch 391: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 193ms/step - accuracy: 0.9596 - loss: 0.1311 - val_accuracy: 0.8609 - val_loss: 0.5664\n",
      "Epoch 392/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9634 - loss: 0.1166\n",
      "Epoch 392: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 192ms/step - accuracy: 0.9634 - loss: 0.1166 - val_accuracy: 0.7782 - val_loss: 1.1801\n",
      "Epoch 393/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9608 - loss: 0.1156\n",
      "Epoch 393: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 191ms/step - accuracy: 0.9608 - loss: 0.1156 - val_accuracy: 0.8315 - val_loss: 0.7995\n",
      "Epoch 394/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.9590 - loss: 0.1329\n",
      "Epoch 394: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 193ms/step - accuracy: 0.9591 - loss: 0.1329 - val_accuracy: 0.8672 - val_loss: 0.5406\n",
      "Epoch 395/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9617 - loss: 0.1325\n",
      "Epoch 395: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 191ms/step - accuracy: 0.9618 - loss: 0.1323 - val_accuracy: 0.8267 - val_loss: 0.8034\n",
      "Epoch 396/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9643 - loss: 0.1138\n",
      "Epoch 396: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 190ms/step - accuracy: 0.9643 - loss: 0.1138 - val_accuracy: 0.8545 - val_loss: 0.6292\n",
      "Epoch 397/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9658 - loss: 0.1152\n",
      "Epoch 397: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 190ms/step - accuracy: 0.9658 - loss: 0.1152 - val_accuracy: 0.8362 - val_loss: 0.7510\n",
      "Epoch 398/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9690 - loss: 0.1073\n",
      "Epoch 398: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 192ms/step - accuracy: 0.9690 - loss: 0.1073 - val_accuracy: 0.8267 - val_loss: 0.7641\n",
      "Epoch 399/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9583 - loss: 0.1305\n",
      "Epoch 399: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 191ms/step - accuracy: 0.9583 - loss: 0.1304 - val_accuracy: 0.8776 - val_loss: 0.4493\n",
      "Epoch 400/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9570 - loss: 0.1268\n",
      "Epoch 400: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 190ms/step - accuracy: 0.9570 - loss: 0.1268 - val_accuracy: 0.8124 - val_loss: 0.9826\n",
      "Epoch 401/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9692 - loss: 0.1166\n",
      "Epoch 401: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 189ms/step - accuracy: 0.9692 - loss: 0.1166 - val_accuracy: 0.8514 - val_loss: 0.6565\n",
      "Epoch 402/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9649 - loss: 0.1147\n",
      "Epoch 402: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 190ms/step - accuracy: 0.9649 - loss: 0.1147 - val_accuracy: 0.8506 - val_loss: 0.6574\n",
      "Epoch 403/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9713 - loss: 0.1037\n",
      "Epoch 403: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 191ms/step - accuracy: 0.9712 - loss: 0.1037 - val_accuracy: 0.8227 - val_loss: 0.9550\n",
      "Epoch 404/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9643 - loss: 0.1128\n",
      "Epoch 404: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 192ms/step - accuracy: 0.9643 - loss: 0.1128 - val_accuracy: 0.8736 - val_loss: 0.4985\n",
      "Epoch 405/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9704 - loss: 0.1084\n",
      "Epoch 405: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 190ms/step - accuracy: 0.9704 - loss: 0.1084 - val_accuracy: 0.8720 - val_loss: 0.4888\n",
      "Epoch 406/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9707 - loss: 0.1042\n",
      "Epoch 406: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 192ms/step - accuracy: 0.9706 - loss: 0.1042 - val_accuracy: 0.8688 - val_loss: 0.4731\n",
      "Epoch 407/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9632 - loss: 0.1182\n",
      "Epoch 407: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 190ms/step - accuracy: 0.9632 - loss: 0.1182 - val_accuracy: 0.8426 - val_loss: 0.7420\n",
      "Epoch 408/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9541 - loss: 0.1355\n",
      "Epoch 408: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 191ms/step - accuracy: 0.9541 - loss: 0.1354 - val_accuracy: 0.8649 - val_loss: 0.4918\n",
      "Epoch 409/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9674 - loss: 0.1147\n",
      "Epoch 409: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 191ms/step - accuracy: 0.9674 - loss: 0.1147 - val_accuracy: 0.8545 - val_loss: 0.6272\n",
      "Epoch 410/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.9578 - loss: 0.1268\n",
      "Epoch 410: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 193ms/step - accuracy: 0.9578 - loss: 0.1268 - val_accuracy: 0.8148 - val_loss: 0.9741\n",
      "Epoch 411/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - accuracy: 0.9694 - loss: 0.0988\n",
      "Epoch 411: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 210ms/step - accuracy: 0.9694 - loss: 0.0989 - val_accuracy: 0.8688 - val_loss: 0.5423\n",
      "Epoch 412/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 0.9698 - loss: 0.1005\n",
      "Epoch 412: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 208ms/step - accuracy: 0.9697 - loss: 0.1006 - val_accuracy: 0.8752 - val_loss: 0.4737\n",
      "Epoch 413/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - accuracy: 0.9667 - loss: 0.1078\n",
      "Epoch 413: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 212ms/step - accuracy: 0.9667 - loss: 0.1078 - val_accuracy: 0.8482 - val_loss: 0.7084\n",
      "Epoch 414/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 0.9749 - loss: 0.0995\n",
      "Epoch 414: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 206ms/step - accuracy: 0.9749 - loss: 0.0996 - val_accuracy: 0.7901 - val_loss: 1.2304\n",
      "Epoch 415/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.9650 - loss: 0.1089\n",
      "Epoch 415: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 197ms/step - accuracy: 0.9650 - loss: 0.1089 - val_accuracy: 0.8561 - val_loss: 0.5565\n",
      "Epoch 416/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.9639 - loss: 0.1077\n",
      "Epoch 416: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 199ms/step - accuracy: 0.9639 - loss: 0.1078 - val_accuracy: 0.6240 - val_loss: 4.1252\n",
      "Epoch 417/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.9531 - loss: 0.1472\n",
      "Epoch 417: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 198ms/step - accuracy: 0.9531 - loss: 0.1470 - val_accuracy: 0.7941 - val_loss: 1.1475\n",
      "Epoch 418/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.9690 - loss: 0.0976\n",
      "Epoch 418: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 198ms/step - accuracy: 0.9690 - loss: 0.0977 - val_accuracy: 0.8704 - val_loss: 0.4927\n",
      "Epoch 419/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.9709 - loss: 0.0996\n",
      "Epoch 419: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 195ms/step - accuracy: 0.9709 - loss: 0.0996 - val_accuracy: 0.8196 - val_loss: 0.9431\n",
      "Epoch 420/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 0.9682 - loss: 0.1030\n",
      "Epoch 420: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 195ms/step - accuracy: 0.9682 - loss: 0.1030 - val_accuracy: 0.8641 - val_loss: 0.5377\n",
      "Epoch 421/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 0.9708 - loss: 0.0997\n",
      "Epoch 421: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 202ms/step - accuracy: 0.9708 - loss: 0.0998 - val_accuracy: 0.8458 - val_loss: 0.6994\n",
      "Epoch 422/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.9661 - loss: 0.1042\n",
      "Epoch 422: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 195ms/step - accuracy: 0.9662 - loss: 0.1042 - val_accuracy: 0.8267 - val_loss: 0.8508\n",
      "Epoch 423/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 0.9726 - loss: 0.0928\n",
      "Epoch 423: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 195ms/step - accuracy: 0.9726 - loss: 0.0928 - val_accuracy: 0.8482 - val_loss: 0.6596\n",
      "Epoch 424/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.9634 - loss: 0.1103\n",
      "Epoch 424: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 196ms/step - accuracy: 0.9635 - loss: 0.1102 - val_accuracy: 0.8068 - val_loss: 1.0270\n",
      "Epoch 425/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.9622 - loss: 0.1110\n",
      "Epoch 425: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 197ms/step - accuracy: 0.9622 - loss: 0.1110 - val_accuracy: 0.8553 - val_loss: 0.6201\n",
      "Epoch 426/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.9643 - loss: 0.1109\n",
      "Epoch 426: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 196ms/step - accuracy: 0.9643 - loss: 0.1108 - val_accuracy: 0.8498 - val_loss: 0.6700\n",
      "Epoch 427/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.9690 - loss: 0.1055\n",
      "Epoch 427: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 195ms/step - accuracy: 0.9690 - loss: 0.1055 - val_accuracy: 0.8792 - val_loss: 0.4483\n",
      "Epoch 428/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.9708 - loss: 0.1105\n",
      "Epoch 428: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 201ms/step - accuracy: 0.9708 - loss: 0.1105 - val_accuracy: 0.8545 - val_loss: 0.5904\n",
      "Epoch 429/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - accuracy: 0.9633 - loss: 0.1169\n",
      "Epoch 429: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 231ms/step - accuracy: 0.9633 - loss: 0.1169 - val_accuracy: 0.8617 - val_loss: 0.6362\n",
      "Epoch 430/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 0.9689 - loss: 0.1031\n",
      "Epoch 430: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 207ms/step - accuracy: 0.9689 - loss: 0.1031 - val_accuracy: 0.6407 - val_loss: 4.5992\n",
      "Epoch 431/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - accuracy: 0.9684 - loss: 0.1213\n",
      "Epoch 431: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 201ms/step - accuracy: 0.9684 - loss: 0.1212 - val_accuracy: 0.8506 - val_loss: 0.6388\n",
      "Epoch 432/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.9719 - loss: 0.0980\n",
      "Epoch 432: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 199ms/step - accuracy: 0.9719 - loss: 0.0980 - val_accuracy: 0.8378 - val_loss: 0.7072\n",
      "Epoch 433/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.9696 - loss: 0.1176\n",
      "Epoch 433: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 196ms/step - accuracy: 0.9696 - loss: 0.1175 - val_accuracy: 0.8323 - val_loss: 0.8020\n",
      "Epoch 434/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 0.9650 - loss: 0.1167\n",
      "Epoch 434: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 200ms/step - accuracy: 0.9650 - loss: 0.1167 - val_accuracy: 0.8617 - val_loss: 0.5997\n",
      "Epoch 435/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.9755 - loss: 0.0936\n",
      "Epoch 435: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 198ms/step - accuracy: 0.9755 - loss: 0.0936 - val_accuracy: 0.8585 - val_loss: 0.5731\n",
      "Epoch 436/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.9684 - loss: 0.1063\n",
      "Epoch 436: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 198ms/step - accuracy: 0.9684 - loss: 0.1063 - val_accuracy: 0.8545 - val_loss: 0.6060\n",
      "Epoch 437/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.9671 - loss: 0.1033\n",
      "Epoch 437: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 199ms/step - accuracy: 0.9671 - loss: 0.1033 - val_accuracy: 0.8625 - val_loss: 0.5868\n",
      "Epoch 438/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.9715 - loss: 0.0962\n",
      "Epoch 438: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 197ms/step - accuracy: 0.9714 - loss: 0.0962 - val_accuracy: 0.8466 - val_loss: 0.6798\n",
      "Epoch 439/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.9692 - loss: 0.1003\n",
      "Epoch 439: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 197ms/step - accuracy: 0.9692 - loss: 0.1003 - val_accuracy: 0.8172 - val_loss: 0.9944\n",
      "Epoch 440/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.9697 - loss: 0.1001\n",
      "Epoch 440: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 196ms/step - accuracy: 0.9697 - loss: 0.1001 - val_accuracy: 0.8021 - val_loss: 1.0738\n",
      "Epoch 441/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.9721 - loss: 0.0950\n",
      "Epoch 441: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 196ms/step - accuracy: 0.9721 - loss: 0.0950 - val_accuracy: 0.8855 - val_loss: 0.4651\n",
      "Epoch 442/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.9719 - loss: 0.0950\n",
      "Epoch 442: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 195ms/step - accuracy: 0.9719 - loss: 0.0951 - val_accuracy: 0.8585 - val_loss: 0.6060\n",
      "Epoch 443/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.9695 - loss: 0.0955\n",
      "Epoch 443: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 197ms/step - accuracy: 0.9695 - loss: 0.0956 - val_accuracy: 0.8275 - val_loss: 0.7372\n",
      "Epoch 444/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 0.9725 - loss: 0.1027\n",
      "Epoch 444: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 207ms/step - accuracy: 0.9725 - loss: 0.1027 - val_accuracy: 0.8307 - val_loss: 0.7869\n",
      "Epoch 445/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - accuracy: 0.9665 - loss: 0.1042\n",
      "Epoch 445: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 200ms/step - accuracy: 0.9665 - loss: 0.1042 - val_accuracy: 0.8410 - val_loss: 0.7479\n",
      "Epoch 446/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.9717 - loss: 0.0929\n",
      "Epoch 446: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 198ms/step - accuracy: 0.9716 - loss: 0.0929 - val_accuracy: 0.8641 - val_loss: 0.5750\n",
      "Epoch 447/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.9710 - loss: 0.0946\n",
      "Epoch 447: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 197ms/step - accuracy: 0.9710 - loss: 0.0946 - val_accuracy: 0.8243 - val_loss: 0.9036\n",
      "Epoch 448/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.9632 - loss: 0.1148\n",
      "Epoch 448: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 197ms/step - accuracy: 0.9632 - loss: 0.1147 - val_accuracy: 0.8521 - val_loss: 0.6807\n",
      "Epoch 449/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.9647 - loss: 0.1087\n",
      "Epoch 449: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 198ms/step - accuracy: 0.9648 - loss: 0.1087 - val_accuracy: 0.7846 - val_loss: 1.2597\n",
      "Epoch 450/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.9684 - loss: 0.1004\n",
      "Epoch 450: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 198ms/step - accuracy: 0.9684 - loss: 0.1004 - val_accuracy: 0.8657 - val_loss: 0.5323\n",
      "Epoch 451/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.9646 - loss: 0.1046\n",
      "Epoch 451: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 195ms/step - accuracy: 0.9646 - loss: 0.1045 - val_accuracy: 0.8776 - val_loss: 0.4845\n",
      "Epoch 452/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.9689 - loss: 0.1058\n",
      "Epoch 452: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 196ms/step - accuracy: 0.9689 - loss: 0.1058 - val_accuracy: 0.8641 - val_loss: 0.5740\n",
      "Epoch 453/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.9754 - loss: 0.0881\n",
      "Epoch 453: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 196ms/step - accuracy: 0.9754 - loss: 0.0882 - val_accuracy: 0.8514 - val_loss: 0.6413\n",
      "Epoch 454/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.9637 - loss: 0.1105\n",
      "Epoch 454: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 195ms/step - accuracy: 0.9637 - loss: 0.1105 - val_accuracy: 0.6272 - val_loss: 2.7517\n",
      "Epoch 455/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.9582 - loss: 0.1381\n",
      "Epoch 455: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 196ms/step - accuracy: 0.9582 - loss: 0.1380 - val_accuracy: 0.8378 - val_loss: 0.7634\n",
      "Epoch 456/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.9695 - loss: 0.1024\n",
      "Epoch 456: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 196ms/step - accuracy: 0.9695 - loss: 0.1024 - val_accuracy: 0.8665 - val_loss: 0.5470\n",
      "Epoch 457/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.9680 - loss: 0.0950\n",
      "Epoch 457: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 195ms/step - accuracy: 0.9680 - loss: 0.0950 - val_accuracy: 0.8092 - val_loss: 1.0457\n",
      "Epoch 458/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.9745 - loss: 0.0950\n",
      "Epoch 458: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 196ms/step - accuracy: 0.9744 - loss: 0.0950 - val_accuracy: 0.8514 - val_loss: 0.6744\n",
      "Epoch 459/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.9764 - loss: 0.0866\n",
      "Epoch 459: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 197ms/step - accuracy: 0.9764 - loss: 0.0866 - val_accuracy: 0.8665 - val_loss: 0.5338\n",
      "Epoch 460/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.9667 - loss: 0.0995\n",
      "Epoch 460: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 197ms/step - accuracy: 0.9667 - loss: 0.0995 - val_accuracy: 0.8362 - val_loss: 0.7249\n",
      "Epoch 461/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.9756 - loss: 0.0899\n",
      "Epoch 461: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 196ms/step - accuracy: 0.9756 - loss: 0.0899 - val_accuracy: 0.8299 - val_loss: 0.9072\n",
      "Epoch 462/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.9710 - loss: 0.0976\n",
      "Epoch 462: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 196ms/step - accuracy: 0.9710 - loss: 0.0976 - val_accuracy: 0.8092 - val_loss: 0.9845\n",
      "Epoch 463/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.9729 - loss: 0.0935\n",
      "Epoch 463: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 197ms/step - accuracy: 0.9729 - loss: 0.0935 - val_accuracy: 0.8275 - val_loss: 0.7917\n",
      "Epoch 464/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.9686 - loss: 0.1128\n",
      "Epoch 464: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 197ms/step - accuracy: 0.9686 - loss: 0.1127 - val_accuracy: 0.8649 - val_loss: 0.5176\n",
      "Epoch 465/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.9651 - loss: 0.1129\n",
      "Epoch 465: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 197ms/step - accuracy: 0.9651 - loss: 0.1128 - val_accuracy: 0.7878 - val_loss: 1.1996\n",
      "Epoch 466/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.9737 - loss: 0.0917\n",
      "Epoch 466: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 199ms/step - accuracy: 0.9737 - loss: 0.0918 - val_accuracy: 0.8442 - val_loss: 0.7060\n",
      "Epoch 467/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.9708 - loss: 0.0840\n",
      "Epoch 467: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 196ms/step - accuracy: 0.9708 - loss: 0.0840 - val_accuracy: 0.8474 - val_loss: 0.6473\n",
      "Epoch 468/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.9722 - loss: 0.0873\n",
      "Epoch 468: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 195ms/step - accuracy: 0.9722 - loss: 0.0873 - val_accuracy: 0.8410 - val_loss: 0.7201\n",
      "Epoch 469/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.9697 - loss: 0.0902\n",
      "Epoch 469: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 195ms/step - accuracy: 0.9697 - loss: 0.0903 - val_accuracy: 0.8323 - val_loss: 0.8595\n",
      "Epoch 470/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.9734 - loss: 0.0902\n",
      "Epoch 470: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 196ms/step - accuracy: 0.9734 - loss: 0.0902 - val_accuracy: 0.8283 - val_loss: 0.8259\n",
      "Epoch 471/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.9752 - loss: 0.0850\n",
      "Epoch 471: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 197ms/step - accuracy: 0.9752 - loss: 0.0850 - val_accuracy: 0.7774 - val_loss: 1.2578\n",
      "Epoch 472/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.9737 - loss: 0.0926\n",
      "Epoch 472: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 198ms/step - accuracy: 0.9737 - loss: 0.0926 - val_accuracy: 0.8355 - val_loss: 0.7507\n",
      "Epoch 473/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.9699 - loss: 0.0998\n",
      "Epoch 473: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 199ms/step - accuracy: 0.9699 - loss: 0.0998 - val_accuracy: 0.8720 - val_loss: 0.5046\n",
      "Epoch 474/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 0.9613 - loss: 0.1091\n",
      "Epoch 474: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 200ms/step - accuracy: 0.9614 - loss: 0.1090 - val_accuracy: 0.8466 - val_loss: 0.7001\n",
      "Epoch 475/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.9712 - loss: 0.0916\n",
      "Epoch 475: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 198ms/step - accuracy: 0.9712 - loss: 0.0916 - val_accuracy: 0.8402 - val_loss: 0.7448\n",
      "Epoch 476/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.9717 - loss: 0.0927\n",
      "Epoch 476: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 196ms/step - accuracy: 0.9718 - loss: 0.0927 - val_accuracy: 0.8816 - val_loss: 0.5125\n",
      "Epoch 477/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.9685 - loss: 0.0948\n",
      "Epoch 477: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 195ms/step - accuracy: 0.9685 - loss: 0.0948 - val_accuracy: 0.8426 - val_loss: 0.6872\n",
      "Epoch 478/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.9715 - loss: 0.0930\n",
      "Epoch 478: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 197ms/step - accuracy: 0.9715 - loss: 0.0930 - val_accuracy: 0.8315 - val_loss: 0.8110\n",
      "Epoch 479/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.9720 - loss: 0.0933\n",
      "Epoch 479: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 198ms/step - accuracy: 0.9720 - loss: 0.0933 - val_accuracy: 0.8148 - val_loss: 0.9719\n",
      "Epoch 480/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.9655 - loss: 0.1022\n",
      "Epoch 480: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 197ms/step - accuracy: 0.9656 - loss: 0.1022 - val_accuracy: 0.8506 - val_loss: 0.6548\n",
      "Epoch 481/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - accuracy: 0.9721 - loss: 0.0912\n",
      "Epoch 481: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 200ms/step - accuracy: 0.9721 - loss: 0.0912 - val_accuracy: 0.8442 - val_loss: 0.7519\n",
      "Epoch 482/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - accuracy: 0.9770 - loss: 0.0775\n",
      "Epoch 482: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 201ms/step - accuracy: 0.9770 - loss: 0.0775 - val_accuracy: 0.7917 - val_loss: 1.2438\n",
      "Epoch 483/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 0.9773 - loss: 0.0871\n",
      "Epoch 483: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 199ms/step - accuracy: 0.9773 - loss: 0.0871 - val_accuracy: 0.8402 - val_loss: 0.7424\n",
      "Epoch 484/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.9752 - loss: 0.0875\n",
      "Epoch 484: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 221ms/step - accuracy: 0.9752 - loss: 0.0875 - val_accuracy: 0.8267 - val_loss: 0.8803\n",
      "Epoch 485/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 0.9798 - loss: 0.0758\n",
      "Epoch 485: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 203ms/step - accuracy: 0.9798 - loss: 0.0759 - val_accuracy: 0.8633 - val_loss: 0.5943\n",
      "Epoch 486/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.9714 - loss: 0.0931\n",
      "Epoch 486: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 196ms/step - accuracy: 0.9714 - loss: 0.0931 - val_accuracy: 0.8545 - val_loss: 0.6759\n",
      "Epoch 487/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.9774 - loss: 0.0800\n",
      "Epoch 487: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 197ms/step - accuracy: 0.9774 - loss: 0.0800 - val_accuracy: 0.8378 - val_loss: 0.7528\n",
      "Epoch 488/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.9722 - loss: 0.0954\n",
      "Epoch 488: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 198ms/step - accuracy: 0.9722 - loss: 0.0954 - val_accuracy: 0.8299 - val_loss: 0.8661\n",
      "Epoch 489/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.9729 - loss: 0.0852\n",
      "Epoch 489: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 199ms/step - accuracy: 0.9729 - loss: 0.0852 - val_accuracy: 0.7417 - val_loss: 2.4969\n",
      "Epoch 490/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 0.9730 - loss: 0.0916\n",
      "Epoch 490: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 200ms/step - accuracy: 0.9730 - loss: 0.0916 - val_accuracy: 0.8553 - val_loss: 0.6545\n",
      "Epoch 491/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.9736 - loss: 0.0870\n",
      "Epoch 491: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 198ms/step - accuracy: 0.9736 - loss: 0.0870 - val_accuracy: 0.8529 - val_loss: 0.6401\n",
      "Epoch 492/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.9782 - loss: 0.0786\n",
      "Epoch 492: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 199ms/step - accuracy: 0.9782 - loss: 0.0786 - val_accuracy: 0.8426 - val_loss: 0.7459\n",
      "Epoch 493/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 0.9756 - loss: 0.0801\n",
      "Epoch 493: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 199ms/step - accuracy: 0.9756 - loss: 0.0801 - val_accuracy: 0.8593 - val_loss: 0.5998\n",
      "Epoch 494/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.9650 - loss: 0.1048\n",
      "Epoch 494: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 199ms/step - accuracy: 0.9651 - loss: 0.1047 - val_accuracy: 0.6876 - val_loss: 2.6764\n",
      "Epoch 495/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.9762 - loss: 0.0856\n",
      "Epoch 495: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 213ms/step - accuracy: 0.9762 - loss: 0.0857 - val_accuracy: 0.8824 - val_loss: 0.4851\n",
      "Epoch 496/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 0.9728 - loss: 0.0959\n",
      "Epoch 496: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 215ms/step - accuracy: 0.9728 - loss: 0.0959 - val_accuracy: 0.8514 - val_loss: 0.6806\n",
      "Epoch 497/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.9794 - loss: 0.0813\n",
      "Epoch 497: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 199ms/step - accuracy: 0.9793 - loss: 0.0813 - val_accuracy: 0.8784 - val_loss: 0.5050\n",
      "Epoch 498/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.9689 - loss: 0.0973\n",
      "Epoch 498: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 195ms/step - accuracy: 0.9690 - loss: 0.0972 - val_accuracy: 0.8529 - val_loss: 0.6715\n",
      "Epoch 499/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.9822 - loss: 0.0674\n",
      "Epoch 499: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 196ms/step - accuracy: 0.9822 - loss: 0.0675 - val_accuracy: 0.8752 - val_loss: 0.4649\n",
      "Epoch 500/500\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.9777 - loss: 0.0787\n",
      "Epoch 500: val_loss did not improve from 0.40098\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 196ms/step - accuracy: 0.9776 - loss: 0.0787 - val_accuracy: 0.8490 - val_loss: 0.6173\n"
     ]
    }
   ],
   "source": [
    "# Train-validation split (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.20, random_state=42, stratify=y_train)\n",
    "\n",
    "# Define model\n",
    "def build_model():\n",
    "    model = Sequential([\n",
    "        Conv1D(64, kernel_size=80, strides=4, padding='same', activation=None, input_shape=(32000, 1)),\n",
    "        BatchNormalization(), ReLU(),\n",
    "        MaxPooling1D(pool_size=4), Dropout(0.1),\n",
    "\n",
    "        Conv1D(64, kernel_size=3, strides=1, padding='same', activation=None),\n",
    "        BatchNormalization(), ReLU(),\n",
    "        Conv1D(64, kernel_size=3, strides=1, padding='same', activation=None),\n",
    "        BatchNormalization(), ReLU(),\n",
    "        MaxPooling1D(pool_size=4), Dropout(0.1),\n",
    "\n",
    "        Conv1D(128, kernel_size=3, strides=1, padding='same', activation=None),\n",
    "        BatchNormalization(), ReLU(),\n",
    "        Conv1D(128, kernel_size=3, strides=1, padding='same', activation=None),\n",
    "        BatchNormalization(), ReLU(),\n",
    "        MaxPooling1D(pool_size=4), Dropout(0.1),\n",
    "\n",
    "        Conv1D(256, kernel_size=3, strides=1, padding='same', activation=None),\n",
    "        BatchNormalization(), ReLU(),\n",
    "        Conv1D(256, kernel_size=3, strides=1, padding='same', activation=None),\n",
    "        BatchNormalization(), ReLU(),\n",
    "        Conv1D(256, kernel_size=3, strides=1, padding='same', activation=None),\n",
    "        BatchNormalization(), ReLU(),\n",
    "        MaxPooling1D(pool_size=4), Dropout(0.1),\n",
    "\n",
    "        Conv1D(512, kernel_size=3, strides=1, padding='same', activation=None),\n",
    "        BatchNormalization(), ReLU(),\n",
    "        Conv1D(512, kernel_size=3, strides=1, padding='same', activation=None),\n",
    "        BatchNormalization(), ReLU(),\n",
    "        Dropout(0.1),\n",
    "\n",
    "        Conv1D(512, kernel_size=3, strides=1, padding='same', activation=None),\n",
    "        BatchNormalization(), ReLU(),\n",
    "        Lambda(lambda x: tf.reduce_mean(x, axis=1)),  # Global average pooling\n",
    "        Dropout(0.2),\n",
    "\n",
    "        Dense(7, activation='softmax')  # 7 classes\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Compile model\n",
    "model = build_model()\n",
    "model.compile(optimizer=SGD(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Callback to save the best model based on validation loss\n",
    "checkpoint = ModelCheckpoint(\"best_model.h5\", monitor=\"val_loss\", save_best_only=True, mode=\"min\", verbose=1)\n",
    "\n",
    "# Train model with callbacks\n",
    "history = model.fit(X_train, y_train, epochs=500, batch_size=32, validation_data=(X_val, y_val), verbose=1, callbacks=[checkpoint])\n",
    "\n",
    "# Load best model\n",
    "model.load_weights(\"best_model.h5\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 40ms/step\n",
      "\n",
      "Classification Report for Training Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9861    0.9956    0.9908      1352\n",
      "           1     0.9882    0.9921    0.9901       506\n",
      "           2     0.9922    0.9742    0.9831      1433\n",
      "           3     0.9770    0.9834    0.9802       906\n",
      "           4     0.9957    0.9852    0.9905       474\n",
      "           5     0.9787    0.9735    0.9761       189\n",
      "           6     0.9066    0.9649    0.9348       171\n",
      "\n",
      "    accuracy                         0.9841      5031\n",
      "   macro avg     0.9749    0.9813    0.9780      5031\n",
      "weighted avg     0.9843    0.9841    0.9841      5031\n",
      "\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step\n",
      "\n",
      "Classification Report for Validation Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9298    0.9793    0.9539       338\n",
      "           1     0.8803    0.8175    0.8477       126\n",
      "           2     0.9008    0.8883    0.8945       358\n",
      "           3     0.8421    0.8458    0.8440       227\n",
      "           4     0.8534    0.8319    0.8426       119\n",
      "           5     0.8182    0.7660    0.7912        47\n",
      "           6     0.7955    0.8140    0.8046        43\n",
      "\n",
      "    accuracy                         0.8855      1258\n",
      "   macro avg     0.8600    0.8490    0.8541      1258\n",
      "weighted avg     0.8848    0.8855    0.8848      1258\n",
      "\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step\n",
      "\n",
      "Classification Report for Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8684    0.8250    0.8462       160\n",
      "           1     0.6829    0.8000    0.7368        70\n",
      "           2     0.9130    0.6146    0.7347       205\n",
      "           3     0.7405    0.8357    0.7852       140\n",
      "           4     0.8026    0.8714    0.8356        70\n",
      "           5     0.5500    0.7333    0.6286        30\n",
      "           6     0.6076    0.9600    0.7442        50\n",
      "\n",
      "    accuracy                         0.7752       725\n",
      "   macro avg     0.7379    0.8057    0.7588       725\n",
      "weighted avg     0.8009    0.7752    0.7753       725\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "def evaluate_model(model, X, y, dataset_name=\"Dataset\"):\n",
    "    y_pred = np.argmax(model.predict(X), axis=1)\n",
    "    print(f\"\\nClassification Report for {dataset_name}:\")\n",
    "    print(classification_report(y, y_pred, digits=4))\n",
    "\n",
    "# Report metrics\n",
    "evaluate_model(model, X_train, y_train, \"Training Set\")\n",
    "evaluate_model(model, X_val, y_val, \"Validation Set\")\n",
    "evaluate_model(model, X_test, y_test, \"Test Set\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
